spectrumbased fault localization sbfl test executions recorded produce program spectrum includes dynamic information test cases respect code executed might simply code coverage hitbased spectrum elaborated count based spectrum code elements treated different levels granularity spectrum also includes test outcomes often simply pass fail spectrum used infer statistical information probability code elements faulty precursor works sbfl couple decades old technique attained popularity software maintenance testing automated program repair communities due relative ease implementation low computation cost basic case although different types program spectra proposed years prevalent approach still simplest one hitbased spectrum simply records binary coverage information code elements upon test case execution coveragebased sbfl straightforward implement us ing existing proﬁling tools corresponding algorithms calculate faultiness simple hence provided fruitful ground large set sbfl techniques proposed literature crucial element algorithms suspiciousness formulas rely four basic statistical measures matrix spectrum metrics count number passing failing test cases execute code element question respectively formulas use numbers rank code elements according suspiciousness researchers experimented various techniques come new formulas combining existing ones applying genetic programming using systematic search automatically infer new ones xie et al examined equivalence hierarchy number formulas yoo et al showed exist perfect scoring formula outperforms known techniques found humans even automatic searchbased methods yet seems still struggling ﬁnd sbfl technique using coverage spectrum produces good enough results practical situations average ranking positions relative program size various popular bench marks defectsj around sir bugsjs although seemingly good results absolute values unacceptably bad around defectsj sir bugsjs average recent user studies report developers tend investigate top top elements recommendation list provided localization methods giving hence improved rank position beyond thresholds probably less useful matter much relative improvement achieve mention application sbfl automated program repair top positions implicitly expected seems reached limit comes coveragebased sbfl approaches additional variation technique could bring modest improvement stateoftheart one possibility include information external spectrum process thus aid localization process beyond scope paper instead concentrate pure spectrumbased approaches particular would like ﬁnd suitable prevalent coveragebased spectra task ﬁrst place important insight coveragebased spectra techniques based assumption code ele ment covered failing tests treated suspicious however easy see overapproximation ieee doi icst original intent look code responsible fault faulty code element must executed failing run also needs cause failureinducing chain toward output statement executed participating corresponding computation responsible failure causes noise sbfl process words instead simple coverage information subset used takes part compu tation precisely concept program slice particular interested backward dynamic program slice computed output statement criterion use information program spectra computed properly dynamic program slice subset coverage information spectrum provide exactly information needed sbfl formulas advantage program slicing practical approaches able provide structural information computation path well program subset question big inﬂuence overapproximation caused coveragebased spectrum compared slicebased depends relative size slices respect coverage information way superﬂuous elements affect sbfl algorithm words effect executed code elements slice ﬁnal ranking lists idea combining program slices sbfl new various approaches overviewed later paper surprisingly relatively studies among utilize backward dynamic slices place coverage program spectrum also studies elaborate relationship coveragebased slicebased spectra typically highlevel measurement results provided main reason modest visibility could pragmatic computing precise slices requires difﬁcult algorithms computation costs high compared simply using coverage paper aim ﬁlling gap providing insight bad coverage spectrum compared slicebased spectrum typical situations deﬁciencies manifest given fact dynamic slices quite small executed instructions average expect large impact overall algorithm effectiveness aim paper discuss concrete slicing techniques effect sbfl conceptual rela tionship backed empirical case study illustrate differences contributions paper following provide theoretical analysis coveragebased spectra necessarily produce suboptimal results compared dynamic slicebased spectra implemented dynamic slicebased sbfl method using precise yet feasible approach case study using wellknown subject program real faults found slicebased spectra performed traditional coveragebased spectra large margin terms faulty elements rank position thoroughly analyzed every fault case study understand typical causes suboptimal performance coveragebased approachadvent selfdriving cars au tonomous vehicles accurate navigation become safetycritical issue prerequisites accurate navigation precise map precise localiza tion makes crucial ensure correct ness algorithms simultaneous localization mapping slam example executing sample input data simulation test environment process called slam testing detect many faults possible established software testing approaches typically aim high coverage either implementation structural testing input space functional testing due lack structure implementations structural testing effective proba bilistic slam algorithms even simple test cases achieve complete structural coverage without triggering interesting behavior contrast idea functional testing partition given input output domain disjoint subdomains elements one equivalence class expected provoke system behavior choosing one representative par tition systematic coverage input space achieved reasonably small number test cases selection test cases equivalence classes made example using border values testing special values randomly selecting test cases main challenge applying functional testing slam complexity input space ie complex maps sensor data slam algorithms hardtopredict behavior paper present approach partition input space slam problem equiva lence classes automatically derive set interesting test cases high coverage regard equivalence classes key idea threefold first identify parameters inﬂuence challenging test case slam algorithms map size sensor accuracy also parameters expose common ﬂaws slam implementations phases inac tivity second deﬁne domainspeciﬁc coverage criteria dividing parameters domains ieee doi icst equivalence classes declarative style third propose method automatically construct challenging test cases high coverage input space based coverage criteria demonstrate applicability approach generating test cases existing fastslam implementation coveragedriven approach improves error detection capability case study number example faults rest paper structured follows sec ii introduces preliminaries sec iii discusses related work sec iv presents systematic test approach sec v coverage criteria sec vi coveragedriven test case generation sec vii presents experimental results sec viii concludespopular approach ﬁnding bugs android apps generate user inputs randomly guided search algorithm send inputs app running emulator actual device many test generation tools based principle introduced recent years improving number crashes detect tools mostly focus producing user inputs button clicks thus simulating users interacting apps user inputs however represent subset inputs android app typically handles besides user inputs android apps also handle interprocess communication concept intents means describing operations performed app event handlers generating intents automatically ie intent fuzzing shown effective way test apps reported reveal many crashes however intents app process event handlers activated depends state app state determined intents also user inputs thus testing via intents via ui inputs may miss possibility triggering relevant crashes android apps android test generators either focus triggering ui events fuzzing intents attempts combine two types testing dynodroid stoat however remains unclear extent use intents instrumental achieving improvements speciﬁcally different input types combined test sequence maximum effectiveness fact android systemlevel events user actions eg screen rotation broadcast intents eg connection network even though apps cannot handle intents available investigating frequently test generator produce either ui systemlevel events could help tuning testing tools achieve better results furthermore question whether intentinduced crashes different crashes produced user inputs example apps may programmed expect invalid eg nullvalued intent parameters crash due lack defensive programming paper describe general framework combining ui events intents test generation extend android test generator mate implement framework uses predetermined probability deciding whether send intent user input app test aut next intents generated randomly using valid structure information statically derived apps conﬁguration bytecode empirically investigate best combine userinput generation intent generation improvements achieved using hybrid approach types crashes found improved approach detail contributions paper follows general framework implementation combining userinputs intents testing android apps empirical comparison fuzzing ui events vs intents resulting coverage crashes apps empirical investigation combination ui event intent fuzzing resulting coverage crashes results show fuzzing intents user inputs leads higher code coverage reveals unique crashes fdroid apps sending user inputs intents combined approach achieves magnitude higher activity coverage using user inputs sending intents furthermore unique crashes found combination ui inputs intents never triggered sending one type event suggesting synergetic effects resulting combination ieee doi icst cidcidcidcidcidcid cidcidcidcidcidcidcid b intents android messaging objects cidcidcidcidcidcidcid cidcidcidcidcidcidcidcidcid cidcidcid cidcidcidcidcidcidcidcid cidcidcidcidcidcidcidcidcid cidcidcidcidcidcidcidcidcid cidcidcidcidcidcidcidcidcidcid cidcidcidcid cidcid cidcidcidcidcid fig architecture android applicationgrowing presence automated speech recognition asr systems modern society motivates need properly test asr systems researchers pro posed series methods test various artiﬁcial intelligence systems eg image classiﬁcation autonomous driv ing etc various perspectives eg fairness robustness recently rise automated audio test case synthesis signiﬁcantly reduced human involvement asr testing process example crossasr tool leverages textto speech tts services automatically generate audio ﬁles texts uses test asr systems intuitively transcription produced asr system equivalent text used generate audio otherwise failed test case asr system uncovered although crossasr demonstrates capability un covering failed test cases successfully still limi tations first fails make efﬁcient use text corpus requires taking input large number texts ﬁnd sufﬁcient failed test cases variation volume gen erated test cases depend solely quality quantity provided text corpus exhaustive selection employed crossasr timeconsuming inefﬁcient second crossasr reports number failed test cases uncovered ﬁnegrained information needed help developers improve asr systems tackle aforementioned limitations propose asdf new automated speech recognition differential testing framework test asr systems tool following features employs text transformation module lever ages known errors asr systems synthesize one audio test cases single text collecting small initial set failed test cases asdf transforms failed texts using various text transformation methods generate test cases example changing tense sentence substituting errorinducing terms words similar phonemes experiments show utiliz ing text transformation module boost number failed texts average details experiment results found github repository asdf also conducts phonetic analysis identify phonemes challenging asr systems transcribe phoneme information provide useful information developers improve asr systems robustnessuniﬁed modeling language uml widely used building different types software models cen tral element model driven engineering mde software development methodology graphical notations uml allow software engineers model different aspects software also enhances collaboration among team members hand object constraint language ocl declarative language enables software engi neers use formal methods specify rules constraints cannot expressed using uml graphical notations hence using uml ocl build software models makes current software development practices rigorous ocl speciﬁcation language offers many features allow users write formal rules uml model exam ple using prepost conditions specify rules operation call uml class diagram recently numerous approaches techniques proposed analyzing verifying uml models annotated ocl approaches tools either provide level case studies semiautomatic tools support verifying ocl constraints however large research gap still remains comprehensive ocl benchmarks exist evaluating ocl analysis tools veriﬁers immediately imposes three challenges uml ocl communities infeasible gain overview better existing tools techniques perform verifying ocl constraints difﬁcult compare individual tools others identify strength limitations technique time consuming design customized benchmark testing particular aspect ocl tool string data typebased veriﬁcation close gap tackle challenges propose approach automatically generate ocl benchmarks particular proposed research focuses following two research questions rq efﬁciently generate large set ocl benchmarks rq effectively evaluate generated ocl bench marksflashbased storages crucial devices widely used reading storing data thanks appearance mlc multi level cell techniques enabled single cell store data larger bit ﬂashbased storages efﬁciently store data become popular devices used practice compared hard disk drives ﬂash based storages better random io performance efﬁcient power consumption smaller sizes etc currently ﬂash based storage devices widely used pc mobiles automotives among others flashbased storages however limited capacity writing data though mlc efﬁcient exacerbates write endurance problem ﬂashbased storage devices ﬂashbased storage reaches certain level write activity also known write endurance stored data longer trusted issue caused data storage medium ﬂashbased storage limited lifespan programerase count figure shows impact mlc technology lifespan ﬂash memory figure shows data stored given cell ﬂash memorys wirte fig endurance ﬂash memory changed respect advance mlc technology endurance declines currently write endurance regarded major criterion evaluating quality ﬂashbased storage different ﬂashbased storages varying degrees endurance therefore important accurately specify guaranteed endurance users objective write endurance test quantify level endurance check devices satisfy requirement market customers shipped write endurance test takes ﬂashbased storage write pattern eg test case measures amount data write storage endure note primary goal endurance test evaluate ﬁrmwares quality rather hardware one main jobs ﬁrmware manage data writes properly success write endurance test depends heavily quality write patterns uses worstcase write pat terns mirror worstcase user scenarios effectively consume devices lifespan throughout test write endurance test aims ﬁnd worstcase write pattern given storage device unfortunately however discovering write pattern manually conducted ﬁeld ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply write pattern l write endurance test endurance storage flashbased storage eg usb fig conventional write endurance test process engineers manually designing worsecase write patterns difﬁcult timeconsuming develop worstcase write patterns test engineers need examine various user scenarios eg work load developer interviews sw development documenta tion review industry standards review experience difﬁcult laborious tasks even experienced test engineers may lead human errors address problem present ares automated technique generating endurance tests ares developed two key ideas first design abstract relative write patterns abstract relative write pattern represents set concrete write patterns likely show similar perfor mance write endurance test using abstract relative write patterns instead concrete write patterns prevents redundant learning signiﬁcantly reduces search space eval uation search space reduced second idea learning algorithm based genetic programming algorithm exploits structure abstract relative write patterns effectively learn good concrete write pattern eg worstcase write pattern used write endurance test evaluation results show ares effective learn ing highquality write patterns perform better existing manually crafted write patterns used samsung electronics use ares produce worst write patterns gb usb ﬂash drive gb micro sd card two popular ﬂash based storage devices used practice two storages ares produced write patterns perform better developed test engineers samsung especially gb usb learned write pattern signiﬁcantly effective baseline manually crafted write pattern contributions contributions summarized follows present ares automated technique generating write endurance tests key ideas abstract relative write patterns reduce search space learning algorithm uses abstract relative write pat terns effectively search qualiﬁed write patterns experimentally demonstrate effectiveness ares comparison existing manually designed write patterns used industrylack mature mutation analysis techniques rust represents serious obstacle ensuring thorough testing programs written safetyfocused programming lan guage compiled lowlevel language rust faces multitude issues comes applying mutation testing languages strictness terms type safety memory restrictions means mutation operators constrained using tailored static analysis furthermore presence unsafe code means special care taken avoid introduction undeﬁned behavior muta tions practical applicability mutation analysis approaches also efﬁcient regard runtime scaling well large numbers tests mutations paper ﬁrst consider mutation analysis rust language devise efﬁcient mutation analysis pipeline rust deﬁne new operators novel language well novel mutation evaluation technique refer batching designed increase efﬁciency mutation analysis overall reduce execution costs batching process grouping individual non conﬂicting mutations together mutant purpose evaluating constituent mutations tests simultaneously rather using processes batching allows efﬁcient inprocess parallelism evaluation making possible use schedulers signiﬁcantly less overhead control entire evaluation nonconﬂicting mu tations sets mutations cannot inﬂuence whether mutations set killed due appear ing distinct parts program technique determines mutations nonconﬂicting conservative static analysis programs functions potentially reached individual tests two mutations appear two different functions exclusively reached two different sets tests respectively candidates evaluation batch mutation analysis pipeline executes tests relevant individual batch parallel since batches mutations require execution larger relevant portions test suite rather selected tests relevant particular mutation technique maximizes test evaluation concurrency beneﬁts illustrated follows supposing two threads nonbatched yet nonnaıve parallel mutation evaluation process might execute partial test suites evaluate mutant ie could utilize thread execute pair tests parallel however would need synchronize end ﬁrst pair tests change mutants restart threads second pair example however batched process would able continue evaluate second pair tests without need synchronize switch mutant thereby producing time saving increases larger numbers tests mutants finally technique creates single metamutant pro gram statically embeds mutations builds idea conditional mutation dynamically enabling sets mutations evaluating individual batches developed tool called mutestrs implements technique used mutestrs evaluate approach critical commonlyused rust programs libraries referred rust crates empirical results show mutestrs applicable range rust subjects reliably generates mutants also demonstrating batching effective reducing mutation analysis runtimes savings possible compared using batching crates studied contributions paper therefore follows set mutation operators suitable rust programs including adaptations existing operators novel oper ators speciﬁcally designed language section iiib ieee doi icst algorithm batching mutations simultaneous parallel efﬁcient mutation evaluation section iiid deﬁnition mutation safety applicable programming languages distinct safe unsafe scopes allowing mutation system programs without fear introducing undeﬁned behavior section iiie results empirical evaluation section iv reduction testing time possible mutation batching practice revealing reduction overall mutation analysis runtime diverse set commonlyused rust subject programs section v tool empirical data available online seeregression testing software testing activity checks changes negatively impacted existing system behavior modern development practices continuous integration ci pipelines commonly used regularly build software run regression test suite straightforward testing strategy retestall executes every test case change however fast feedback developers crucial testing resources limited executing tests large test suite often prohibitively costly address problem regression test selection rts studied since reduce testing effort running subset test cases rts technique considered safe subset test cases contains tests potentially expose fault ivu trafﬁc technologies ci pipelines execute regression test suite consisting unit integration system tests written c java pull requests merged release branches however running ivu trafﬁc technologies one worlds leading providers public transport software solutions full test suite pull request yields intolerable feedback times several hours despite high degree test parallelization therefore developed successfully deployed ﬁlelevel rts technique java tests ivu prior work yet due complex nature multi language code base ivu two problems remained unsolved ﬁrst majority million lines code loc test suite written c c regression tests supported current rts solution ﬁlelevel techniques impractical languages compile large binary ﬁles second exist several thousand java tests use java native interface jni interact dynamiclink libraries dlls built c code hence c source ﬁle part dll changes every test accessing binary ﬁle selected short ﬁlelevel pertest execution traces imprecise java tests use crosslanguage links c binaries although several languageagnostic yet inherently unsafe rts approaches reportedly used industry research safe rts c software relatively sparse early rts research considered binary compiled languages c c recently proposed rts techniques focus java since c size frequency regression testing well development tool chains signiﬁcantly evolved insights design beneﬁt rts modern largescale industrial c software largely missing knowledge past decade two published studies proposed rts techniques c software however techniques suitable c projects using llvm compiler infrastructure cope crosslanguage links c binaries ignore changes external ﬁles eg noncode artifacts either support dynamic linking libraries operating systems linux new approaches rts modern c software industryscale evaluation therefore essential address gaps research practice paper present binaryrts novel rts tech nique software using c binaries throughout testing process analyzed tests written c ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply language interoperability native binaries eg java tests crosslanguage links using jni binaryrts leverages dynamic binary instrumentation collect covered functions accessed external ﬁles test allows accurate reliable test selection changes c binaries noncode artifacts source ﬁles domain speciﬁc languages properly attributed affected tests instrumentation analysis within binaryrts compiler agnostic supports c c binaries outofthebox transferred different platforms well operating systems compiled languages evaluate binaryrts ivus largescale ci infrastruc ture analyzing pull requests across two release branches covering commits investigate saved testing effort binaryrts measure test selection ratio c test suite crosslanguage java test suite results show binaryrts selects average c tests java tests binaryrts never fails select tests reveal actual regressions studied pull requests due promising results ivu currently deploying binaryrts release branches provide binaryrts ﬁrst publicly available c rts tool foster regression testing research cgarciaucmes ﬁlipporiccaunigeit ejwucscedu abstractmodern web applications complex used tasks primary importance quality must guaranteed highest levels reason testing techniques eg endtoend required validate overall behavior web applications one popular tools testing web applications selenium webdriver selenium webdriver automates browser mimic real user actions web selenium made testing easier many teams worldwide still share challenges better understand challenges corresponding solutions adopted decided undertake personal opinion survey industry total highly skilled participants focus selenium ecosystem results allow understanding challenges consid ered relevant professionals daily practice techniques approaches tools adopt face therefore study useful practitioners interested understanding solve problems face every day researchers interested proposing innovative solutions problems solid industrial impact index termsendtoend testing web testing selenium webdriver personal opinion survey challenges endtoend ee testing web applications type black box testing based concept test scenario turned lot effective improving quality applications test reason many software companies around world adopted nowadays selenium webdriver considered defacto library developing ee tests web applications selenium umbrella project provide browser automation features impersonate users interact browsers chrome firefox edge automatically recent study context software testing cerioli et al appoints selenium one used valuable testing library today selenium one best tools automating ee test cases like anything good drawbacks without doubt selenium makes testing phase straightforward challenges software developers testers face using among one particularly insidious treated academic ﬁeld ﬂakiness condition test cases fail apparent reason nondeterministic way paper presents results online survey carried professionals understand better characterize relevant challenges ee testing selenium webdriver total experienced participants countries four different continents completed survey results reveal main challenges developers face practitioners try solve problems eg ﬂakiness fragile tests arise daily using selenium paper organized follows sect ii provides essential background ee testing presents challenges considered survey sect iii describes design procedure personal opinion survey conducted sect iv presents results lists possible threats validity finally sect v reports related literature sect vi concludes papervirtual environmentbased test widely adopted automakers check safety performance au tonomous driving software largescale synthetic road environments could easily done physical environment example software reads series synthetic road images instead real ones results control inputs eg speed lane changes tested many tricky driving scenarios severe weather conditions unexpected pedestrian crossing virtual environment consists many types static dynamic objects trafﬁc signs trees buildings static objects pedestrians vehicles dynamic objects different synthetic driving scenarios created depending objects placed interact among objects side objects typically placed alongside roadway help safer driving eg trafﬁc signs lights provide nondriving related aspects eg trees buildings advertisement signs according nhtsa accident report collision side objects constantly recorded around types crashes years addition side objects directly obstruct driving path level autonomy increases software baekgyu kim corresponding author work partly supported national research foundation koreanrf grant rcc institute information communications tech nology planning evaluation iitp grant funded korea governmentmsit side objects b trees c trees lights trees lights safety cones buildings fig example road side objects whose autonomous decision typically made various sensors may interpret unexpected way impeding ideal behavior particular perceptionbased steering control enables car stay within expected lanes predicting series steering angles based camera images provide information current car position respect lane however indicated several prior works presence side objects camera images may play role disturbance accurately predicting steer angle prediction error accumulated time may signiﬁcantly reduce driving comfort eventually lead lane departure much research conducted generate virtual driving scenarios abdessalem et al proposed way generate critical test scenarios based learnable evolutionary algorithms majumdar et al proposed paracosm frame work generates test cases via programmatically describing complex driving scenarios gambi et al proposed way generate test cases speciﬁc crash scenarios po lice reports works applied rulebased approach procedurally generate complex city environments according predeﬁned goals procedures works took formal approaches precisely describe test requirements virtual driving scenarios auto generated machine learning domain complex road layouts vehicle trajectories generated using recurrent neural network also research describe driving scenarios precisely help constructing realistic environments systematic fashion however aforementioned techniques limited ap plicability since generate roadway ii place preselected sideobjects predeﬁned locations iii conﬁgure distance parameters side object category ieee doi icst independently existing virtual simulation software carla prescan carsim consider test generation problem aims automat ically placing side objects conforming geometric dependency especially test behavior perception based steering control firstly formulate geometric constraints side objects constraints involve geometric distances patterns side object placed respect roadway side objects secondly propose distribution criteria characterize sparsely densely number side objects placed along roadway particular introduce two distribution criteria waypoint distribution density distribution quantiﬁes amount pattern side objects placed region interest speciﬁcally among inﬁnite number placement options criteria force placement strategy achieve expected number side objects according particular geographical pat tern thirdly smt satisﬁability modulo theoriesbased placement algorithm proposed automatically determine positions side objects ie dimensional coordi nates conforming constraints distribution criteria scalability placement algorithm shown fast hundreds side objects generated presence linear nonlinear geometric constraints also give case study demonstrating convo lutional neural network cnn model predicting steering wheel angle inspired nvidias work shows different behavior several environments generated different constraints distribution criteria make following contributions formalizing side object placement constraints respect road geometry expressed opendrive speciﬁcation designing waypoint density distribution cri teria geometric distribution side objects developing smtbased algorithm automati cally places side objects conforming constraints distribution criteria case study training testing convolutional neural network cnn predict steering angle generated virtual road environmentfculpt abstractembedded systems present many devices internet things drones cyberphysical systems software security devices critical depending context integrated role play eg water plants vehicles c core language used develop software devices known missing bounds data types leads vulnerabilities buffer overﬂows vulnerabilities exploited cause severe damage put human life danger one concerns vulnerable c programs correct code automatically adequately employing secure code remove existing vulnerabilities avoid attacks however task faces challenges namely determining code needed remove time ensuring correct behaviour program insert verifying correction applied secure effectively removes vulnerabilities another challenge accomplish elements automated manner paper presents approach automatically discovering conﬁrming potential vulnerabilities application applies code correction ﬁx vulnerable code conﬁrmed vulnerabilities validates new code implemented approach resulting corca tool evaluated set tests real applications experimental results showed tool capable detecting vulnerabilities ﬁxing correctly index termscode repair buffer overﬂow vulnerabilities static analysis fuzzing software security advancement technologies growth use software systems daily globally raised several questions related security software used everyday life use several devices eg smartphones computers vehicles whose operation depends software use devices constant development evolution always searching bringing new features better user experience software become robust complex provide features increase complexity size favours appearance bugs code since becomes harder analyze ensure correctness certain conditions systems submitted bugs cause appearance exploitable vulnerabilities leading corruption systems existence bugs systems occurs due usage unsafe languages unintentional errors introduced programmers although today concern software security unsafe languages still widely used errors continue made one main problems building secure systems c one unsafe used languages development software products several areas even appearance new languages remains one used time c lacks checking mechanisms buffer limits leaving developer entirely responsible correct memory resource management weaknesses root buffer overﬂows bo vulnerabilities range ﬁrst place cwes top dangerous weaknesses exploitation bo existing critical safety systems railways autonomous cars catastrophic effects manufacturers endanger human lives however c contains safe functions used avoid introducing vulnerabilities invalidating attacks developers may aware functions even know use properly currently great demand tools help de velopment secure software overcome aforementioned difﬁculties however tools hard use report vulnerabilities real ie false positives reason many tools require developers manually analyze reported results consumes signiﬁcant amount developers time moreover time ineffective look inexistent vulnerabilities source code tools use different techniques detect vulnerabilities fuzzing used ability exploit fuzzing give information code putting task programmers side challenging know security programming static analysis combination fuzzing recently machine learning approaches proposed identify bugs code suffer imprecision putting effort checking output veracity developers side hence necessary ﬁnd ways automatically detect ﬂaws remove employing security program ming helpful developers existence tools capable automatically detecting ﬁxing vulnerabilities would make developers tasks easier decrease time needed write secure code automatic program repair apr c tools available capabili ties limitations producing syntactically incorrect code verifying effectiveness inserted ﬁxes moreover security existing ones verify correctness ﬁxed code leave programs ieee doi icst syntactically incorrect hence must carry tools remove vulnerabilities c programs correcting code making safe furthermore necessary one hand conﬁrm existence vulnerabilities found reduction false positives hand verify correctness effectiveness corrections made paper proposes approach automatically detecting correcting bo vulnerabilities c programs idea behind approach combine techniques static anal ysis fuzzing apr discover bos statically conﬁrm presence fuzzing remove vulnerabilities repairing code testing corrections effectiveness paper also presents correction c automatically corca tool implements approach corca ﬁrst hits sensitive sinks associated bo eg strcpy existing program testing put next extracts code slice single data ﬂow starts buffer declaration ends sensitive sink function hinted composes slice program syntactically correct executable afterwards fuzzes slice programs conﬁrm ones really vulnerable corrects applying ﬁxes small pieces code fixes generated inserted automatically contain right code needed remove vulnerabili ties next ﬁxed slice programs compiled submitted validation process fuzzed test cases exploited vulnerabilities contained therein new test cases driven former lastly new release put produced validated ﬁxes tool validated programs sard assessed real applications discovered zerodays vulnerabilities ie previously unknown vulnerabilities correctly ﬁxed vulnerable applications main contributions paper approach searching potential bo vulnerabilities based static analysis conﬁrmation generation test cases derived fuzzing automatic creation ﬁxes remove vulnerabilities application assessment effectiveness tool capable ﬂagging con ﬁrming bo vulnerabilities programs written c correcting verifying effectiveness corrections automated way experimental evaluation shows ability tool detect known zeroday vulnerabilities remove effectivelyresults indicate commits direlated changes affect tests dirts identiﬁes affected tests clearly missed static rts tool starts still dirts comparatively efﬁcient precise publish dirts rts tool either used safety extension existing rts tools standalone rts solution index termssoftware testing regression test selection de pendency injection static program analysis crosslanguage links regression testing regularly performed software systems ensure changes inadvertently affected existing system behavior simplest yet expensive retestall strategy execute every test case test suite introduced change yet increasingly large test suites shorter development lifecycles strategy often becomes infeasible regression test selection rts aims minimize regression testing effort reexecuting tests may yield different result due changes code rts technique safe affected tests correctly identiﬁed relate changes tests affect rts techniques typically maintain dependency graph code entities eg functions test code entity changed tests depend entity selected based type program analysis apply generate dependency graph rts techniques divided static dynamic techniques several static dynamic rts techniques proposed speciﬁcally languages targeting java virtual machine jvm java techniques originally designed safe assumption java code changes however zhu et al discovered assumption may hold true practice using tool rtscheck found safety violations stateoftheart rts tools due changes nonjava source ﬁles eg xml ﬁles recently shi et al well elsner et al identiﬁed cases rts tools able recognize java xml code changes may alter runtime behavior tests dependency injection di objects dynamically created injected although di widely adopted design principle reduce coupling objectoriented softwareit heavily used java ee spring contemporary rts tools lack adequate di support paper investigate rts prone unsafe confronted di mechanisms based ﬁndings design implement dirts static rts tool java aims address shortcomings existing rts tools regarding di dirts leverages efﬁcient static java source code analysis construct dependency graph additional edges related di since di frameworks often allow conﬁguration xml dirts also acknowledges crosslanguage links parses metadata xml ﬁles currently dirts supports three popular di frameworks java spring guice cdi give software engineers ﬂexibility stick established development processes tooling dirts either used safety extension existing rts tools standalone rts tool evaluate dirts empirical study commits opensource java projects make use di ﬁnd commits existing rts tools might unsafe compare dirts starts static rts tool prior research ﬁnd analyzed commits direlated changes affect tests whereas starts misses select affected tests commits despite superior safety direlated changes dirts comparable efﬁciency authors contributed equally dirts github httpsgithubcomtumidirts dirts demo video spring httpsspringio guice httpsgithubcomgoogleguice jakarta cdi httpsjakartaeespeciﬁcationscdi ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply precision contrary starts require fully compiled java workspace giving ﬂexibility selective build optimization examples di frameworks aim inject object implementation interface datasource shown listing loosely inspired javaxsqldatasource summary paper makes following contributions diaware rts ﬁrst investigate problem unsafe rts behavior related di mechanisms dirts tool implement dirts static rts tool java used safety extension existing rts tools well standalone rts solution supports method classlevel test selection empirical study present empirical study eval uate efﬁciency effectiveness dirts prevalence direlated rts safety violations open source java projects dirts safer rts tool starts also comparatively efﬁcient effectivematias duran national institute informatics tokyo japan matiasidurannweb applications ubiquitous signiﬁcant inﬂuence many aspects daily lives internet banking ecommerce travel planning getting latest news society relies web applications even creasing extents many scenarios web applications must support millions concurrent users hence assessing whether systems behave expected also heavy loads crucial aspect improving system quality indeed number issues related performance eg unacceptable response times memory leaks even functional issues eg race conditions buffer overﬂows may manifest system load kinds issues directly affect customerperceived quality systems often cost companies millions dollars performance testing aims generating synthetic yet realis tic workloads system test sut monitoring behavior execution said workloads uncover loadrelated problems web applications domain workloads basically sequences requests produced number concurrent users performing possibly different use cases given time period example perfor mance testing would possible simulate high load spikes could expected black friday estore evaluate whether user experience remains acceptable crucial activity performance testing design proper synthetic workloads ie deciding many simulated users interact system said interaction carried since deﬁning realistic workloads timeconsuming complex activity literature many approaches tools proposed support testers design workloads works aim generating realistic workloads starting real user behaviors inferred analyzing session logs however industrial academic experience found solutions present drawbacks limiting earlystage detection defects productivity performance testers indeed proposed solutions typically require sut actually deployed order collect real user behaviors thus applied solutions offer limited sup ﬁrst release moreover port performance testers tedious errorprone timeconsuming task correlating inputoutput data subsequent requests interrequests dependencies lastly solutions often struggle keep pace technical evolutions example support novel protocols websockets increasingly common modern web applications paper present eeloader new approach automate deﬁnition performance testing workloads web applications key novelty behind proposal leverage endtoend functional tests rather systems logs infer user interaction patterns way functional ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply tests deﬁned actual deployment sut eeloader allows testers generate workloads earlier stage system lifecycle moreover eeloader includes customizable heuristic automatically detect interrequest dependencies features full support websocket proto col graphical user interface better support testers duties evaluated eeloader industrial case study based ﬁve different workloads modern microservicebased web application makes use websocket protocol results show workloads generated eeloader induce loads sut cases statistically comparable induced workloads manually generated practitioners working industrial partner requiring fraction time realized eeloader source code publicly available interested practitioners researchers paper structured follows section ii presents performance testing process key phases together overview related work literature well comparison common performance testing tools state practice section iii describe detail proposed approach section iv describes case study conducted assess effectiveness proposal generating realistic workloads section v present results case study lastly section vi give closing remarks discuss future workswriting test cases hand costly time consuming especially dealing webenterprise applications backends cloud applications often developed web services including rest graphql rpc eg grpc apis considering wide use industry recent increase interest research community design new techniques automatically test web apis recent years many techniques tools proposed fuzz restful apis including alpha betic order example bboxrt evomaster restct restest restler resttestgen schemathesis however less attention literature project received funding european research coun cil erc european unions horizon research innovation programme grant agreement partially ubacyt ba pict spent fuzzing kinds web services like graphql rpc apis authors evomaster search based fuzzer supports kinds web services ie rest graphql rpc apis evo master supports whitebox blackbox testing far know among different tools literature seems evomaster still one supports whitebox testing ie tools black box fuzzers since inception opensource project one challenge ﬁnd suitable apis exper imentation ﬁrst published work evomaster used apis featuresservice scout api github api one industrial partners time ﬁnding restful apis opensource repositories trivial search functionality access today available time eg search projects using speciﬁc libraries experiments whitebox testing requires code analyses focused one programming language ie java restricted could used experimentation eg api written python ruby several potential apis could selected experimentation large majority either documentation would compile required lot manual effort get started eg build war ﬁles manually upload jee container like jboss whitebox experiments enable gener ation actual test cases eg junit format could used well regression testing need able programmatically start stop reset eg state sql database tested apis system test sut used experiments wrote driver classes carry tasks programmatically discussed details section iv classes also provide necessary information fuzzers effectively test apis like example authentication information eg usernames passwords required writing driver ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply classes require manual effort researchers practitioners seems complicated task eg particularly case practitioners use fuzzers like evomaster industry large microservice architectures hundreds distinct web services like example meituan large ecommerce enterprise million customers often web services used microservice architecture share technologies driver class written one web service trivial others finding preparing suts experiments web ser vices different exam ple preparing experiments unit testing evo suite prepared sf corpus simply took projects random plus popular projects time main opensource repository sourceforge experiments unit testing needed able compile projects projects could kind need able run appli cations example system testing restful api api using sql database postgres needs running fortunately nowadays fully automated tools like docker libraries like testcontainers something driver classes reasons considering issues ﬁnding preparing suitable suts experimentation fuzzing web services since collected suts driver classes single github repository called emb driver classes rely functionality utilities published library maven central jvm languages npm nodejs languages year added new suts emb provide larger variegated corpus suts experimentation used better evaluate novel techniques designed evomaster eg sql handling adaptive hypermutation originally emb stood evomaster benchmark prepared support experiments evomaster driver classes technically used fuzzer eg programmatically setup experiment conﬁgurations able generate selfcontained test cases used regression testing example evomaster uses driver classes generated test suite ﬁles sut started test case run eg junit beforeall function reset test case execution ﬁnally stopped test cases test suite executed besides used group experiments evo master also research groups used emb studies example include extensions evomaster eg well used comparisons different fuzzers eg paper provides following contributions present emb curated corpus web services used experimentation software testing research use already years since extended year new suts provide implementation driver classes involving thousands lines code together library support explanation use enable fuzzers besides evomaster generate selfcontained test cases introductory video emb currently accessed httpsyoutubewjsatglewautomated program repair aims reduce cost software debugging maintenance recent advancement deep learning availability massive opensource code corpus neural program repair gaining signiﬁcant traction neural program repair learn repetitive ﬁx patterns numerous samples developer written patch automatically existing studies developer behaviour code comprehension program repair tasks show usage inference contextual information important part development process consequently essential leverage contextual information according need source code processing task current neural program repair techniques employ contextual information buggy statement surrounding context various ways information limited buggy state contextual ment surrounding lines code enclosing function enclosing class enclosing ﬁle encapsulated ast subtree despite promising results achieved existing neural pro gram repair techniques several key limitations concern selection representation contextual relation namely focus buggy statement choose contextual information adhoc fashion eg pre deﬁned code token limit number nodes abstract syntax tree ast treat code sequence tokens ast embed semantic relationships code elements ignore control data ﬂow dependencies program entities variables statements function calls pertaining bug ﬁx program repair task effective context needs encode possibly related information pertaining buggy line meaningful ﬁx bug call repair ingredient hypothesis contextual information based program dependencies control data ﬂow could leveraged extract repair ingredients instead treating context adhoc way paper present framework glance graph tosequence learning context embedding lever ages contextual information using program analysis repair learning apply backward slicing extract related repair ingredients pertaining buggy statement isolate ﬁx ingredient extract control data ﬂow dependencies static program analysis embed context graph call graph control data dependencies flowaugmented graph fag graph explicit control data ﬂow edges makes code amenable machine learning employ graphto sequence architecture learning patterns graphical representation code paper makes following contributions graphbased technique called glance neural pro gram repair tasks leverages contextual information using static program analysis novel ﬂowaugmented graph representing code graph augmented contextual information combines backward slicing isolating repair ingre dients b buggy statement context demarcation c explicit modelling control data ﬂow edges capture relevant semantic relationships program elements empirical evaluation glance six state oftheart techniques assess effectiveness quantitative ablation analyses glance achieves accuracy ﬁxing bugs outperforming ieee doi icst two topperforming approaches coconut katana respectively replication package publicly available empirical results show employing novel ﬂow augmented graph abstraction framing program repair objective graphtosequence learning task effec tive improving accuracy glance backward slicing extracts contextual information reducing noise learning model furthermore results indicate explicit modelling control dataﬂow edges helps neural model learn underlying code structure given current techniques rely adhoc context representation study highlights selection context needs systematic program analysis techniques helpful selecting encoding relevant contextual information learningbased repairfast collaborative large scale development enabled use continuous integration monorepository monorepo environment source code stored single shared repository monorepo developers share single source truth state code builds made head recent commit repository using source code libraries dependencies rather versioned precompiled archives enables among things uniﬁed versioning atomic changes large scale refactorings code reuse cross team collaboration ﬂexible code ownership boundaries large scale monorepos google microsoft facebook require advanced systems ensuring changes submitted repository properly tested validated continuous integration ci system practice automatically integrating changes code repository serves source truth organization modern environments integration involves performing textual merge required add change also veriﬁcation tasks ensuring software compiles automated tests pass new change integrated incorporated main development branch due resource constraints tests run speciﬁc versions called milestones google many tests may skipped affected intervening changes determined static build dependencies builds tests p n pf p changes f ff p pp f ff milestone commits changes capacity run tests test affected change milestone commit test run mul tiple times deflake n test flaky nondeterministic test throttled p test passed f test failed test run fig example timeline showing tests run continuous integration system tests run milestone changes backend machine execution capacity run tests tests throttled test owner isnt paying continuous testing tests run multple times deﬂake ﬁnally tests run statically affected change process illustrated figure test considered passing version b passing result recent preceding affecting version formally exists version test passing b exist intervening version c c b affects test test passing version projects status considered passing version b tests passing using deﬁnition version b test failing consistently milestone version may necessarily mean version introduced change broke test shown figure one changes previous milestone test run may introduced breaking change figuring version introduced breakage called culprit ﬁnding many companies employ automated culprit ﬁnding systems systems typically implement possibly n way bisect search similar one built git version control system gits bisect command runs binary search versions ﬁrst known breaking version last known passing version identify ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply version broke test typically culprit ﬁnding needed either tests run every change regression found new test created exercise google environment two problems traditional bisection algorithm account ﬂaky nondeterministic tests using kreruns deﬂake search accuracy plateaus build cost continues increase linearly paper proposes new method culprit ﬁnding robust nondeterministic ﬂaky test behavior identify culprit logarithmic builds best case using prior information accelerate search contributions flake aware culprit finding facf algorithm mathematical model culprit ﬁnding adjusting nondeterministic test behavior large scale empirical study facf googles mono repository comparing performance traditional bisect algorithm study also evaluates effectiveness optimiza tions facf b adding deﬂaking runs bisectmotivation video gaming industry thrives expected record revenue billion annual growth rate gain foothold emerging market developers ensure best gaming experience possible achieved via extensive testing procedures however video games created incrementally even developed indeﬁnitely resulting many program increments tested even though fully automated testing games could relieve developers tedious task look current industry practices reveals dire need research companies still test manually besides entertaining player video games also increas ingly used programming education games keep students motivated demonstrating crucial programming concepts although even experienced programmers rely integrated development tools students left lack tools assist learning journey thus work automated game testing required students practitioners cannot validate correctness programs also use generated inputs dynamic program analysis many challenges arise developing fully automated game testing tools first games aim entertain players increasingly complex tasks renders existing testing approaches useless comes ﬁnding suitable test input sequences advanced program states may reached playing games meaningfully second games keep players engaged via randomised program haviour renders previously generated input sequences useless since longer lead states generation process hence test input generators must adapt changes program behaviour ensure deterministic testing without limiting number bugs found introducing ﬁxed seeds random number generators fi nally randomised programs exacerbate test oracle problem involve explosion valid program states neuroevolution successfully used optimise net works towards mastering various video game genres however networks trained win games optimised reach program statements reliably observed program states systematically validated besides actively playing games testing tools also navigate gui intensive states menu settings limitation networks trained gameplay expect frequent program state changes searchbased software testing sbst shown generate suitable test suites domains program statements easier reach dependent randomisation thus thesis aims combine neuroevolution sbst automatically generate test suites neural networks capable validating correctness games reliably even face program randomisationproducing robust implementations memory managers still nowadays challenging task defects garbage collec tion algorithms produce subtle effects revealed later program execution memory corruptions problem exacerbated fact garbage collection algorithms deal lowlevel aspects efﬁcient chromium project ﬁnds since highseverity bugs due memory unsafety useafterfree errors finding reproducing debugging bugs complex timeconsuming see section ii existing work proposes perform static veriﬁcations algorithms using theorem collection gc garbage work funded inria alamvic action exploratoire provers model checking approaches heavyweight implement execute even expense requiring speciﬁc techniques optimize see section vi existing fuzzing techniques applied virtual machines vm aimed testing time jit compiler engines propose generally use template programs mutated argue however approaches although shown suitable ﬁnd compilation errors efﬁcient ﬁnding garbage collection bugs show set programs large majority stable allocation patterns present similar allocation patterns moreover patterns fail cover memory manager corner cases see section iid article propose heap fuzzing lightweight test generation approach automatically generates test scenar ios targeting memory managers garbage collectors propose shortcut vms jit execution engines fuzz directly vm memory managers directly fuzzing memory manager allows us control aspects location objects allocated lowlevel events gc invocations parameters solution generates large sequences random heap events exercise garbage collection algorithms generate vm crashes ﬁnd bugs combine fuzzing test reduction algorithm ﬁnds smaller subset events reproducing issue see section iii implemented approach top pharo virtual machine presents mature implementation stable production usage decade built three heap fuzzers tailored vm experts found six different realworld bugs drastically outperforming fully random heap fuzzer found nothing number runs show combined test reduction techniques bugs found reproduced trivial sequences events easy debug see section iv paper contributions ﬁrst implementation best knowledge heap fuzzer tests memory managers garbage ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply collection algorithms c weak references ephemeron finalization empirical evidence lightweight heap fuzzer imple mentation using simple random gc events combination vm expert heuristics capable ﬁnding realworld bugs alphastate ephemeron implementation also stable underproduction compactor gc analysis showing hitting failures approach happens high probability correct heuristics expertguided fuzzers ﬁnd bugs runs low timeouts outperforming fully random fuzzer ﬁnds nothing empirical evidence showing bugs duced trivial sequences easy debug synthesize normal testse large uncovered parts pro gram semantically partitioned largely unreachable given current corpus inputs consideration human use categorization ranking compartments directly focus manual effort finding fashioning inputs make compartments available future fuzzing evaluate effect compartment analysis seven projects within ossfuzz corpus see coverage improvements afl high median observe determination compartments highly stable thus done early fuzzing campaign maximizing potential impact fuzz testing fuzzing effective auto mated vulnerability discovery technique available today widely used industry subject intense research recent years however dynamic testing technique fuzzing fundamentally limitedif code executed fuzzing cannot discover bugs within code coverage usually measured terms basic blocks edges exeucted least necessary condition surfacing unknown bugs note sufficient condition block containing bug executed mean bug triggered without satisfying additional constraints program state general case however achieving high coverage rate remains vitally important hurdle overcome using fuzzing discover new vulnerabilities unfortunately fuzzing known unable cover program test even using simple block edge coverage metrics empirical studies repeatedly shown coverage tends plateau relatively quickly usually within hours recent work examined phenomenon theo retical perspective postulating empirical power law governing difficulty achieving new coverage new coverage becomes exponentially difficult obtain time numerous approaches proposed part full surmount coverage barrier seed selection trimming reduce number wasteful trials inputs unlikely produce new coverage ii sophisticated fuzz configuration scheduling algorithms iii improving mutation operator scheduling iv input region prioritization v hybrid fuzzing approaches use concolic execution assist conventional greybox mutational fuzzer vi learning human input among others despite enormous research investment improving fuzzers cover new code time across individual fuzzing campaigns remains open central problem field work propose homo machina hmfuzzing presents conclusions derived incremental fuzzing results human turn help guide fuzzer achieve greater coverage would otherwise possible currently humans primarily intervene fuzzing campaigns analyzing coverage reports either providing new seeds modifying test harnesses hmfuzzing aims improve critical yet understudied manual aspect realworld fuzzing building key insight humans substantially capable automated techniques covering new code also relatively limited budget apply expertise one example hmfuzzing introduce com partment analysis compartment analysis designed run periodically fuzzing campaign incremental coverage achieved point goal analysis identify compartments code dominated block adjacent coverage frontier covered would likely maximize overall coverage given fixed resource budget interprocedural controlflow graph icfg program test used identify nodes dominate greatest number basic blocks considering intra interprocedural edges compartments ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply filtered according saturated given current fuzzing corpus retaining severely undercovered entirely uncovered compartments dynamic dataflow analysis used conjunction icfg provide additional advice analyst conditionals gate compartments depend upon inputs fuzzing test harness analysis orders compartments weighting function returns heavy hitters security analyst analyst use signals extracted compartments adjust test harness augment input queue unlock compartments technique improve coverage remainder fuzzing campaign also future campaigns well compartment analysis systematically enables security analyst judiciously intervene assist fuzzers covering code likely could cover evaluation applies compartment analysis test set programs corresponding fuzzing harnesses google fuzzbench corpus overall results demonstrate compartment analysis effective obtaining substantial improvements coverage gains least six seven cases increase one human effort estimated several hours per program modest given gains interests open science reproducibility opensource prototype implementation data publication summary paper makes following contributions propose compartment analysis novel human intervention fuzz testing significantly improve coverage current future campaigns implement prototype analysis suggests rankordered interventions terms testing harness modifications input seed set augmentation evaluate prototype elements google fuzzbench corpus demonstrate sig nificant improvements coverage baseline campaignse mutants faults semantic relationship improving effectivenessin cost qualityof mutation testing may lie better understanding relationship particular regard individual mutation operators types couple real faults study examine coupling mutants produced mutation operators real faults using scale based number failing tests reasons failure ultimately observed mutants strongly coupled real faults faults least one strongly coupled mutant identify examine mutation operators highest median coupling well operators tend produce noncompiling mutants undetected mutants mutants cause tests detect actual fault fail also examine coupling could used ﬁlter set operators employed leading potentially signiﬁcant cost savings mutation testing ﬁndings could lead improvements mutation testing applied improved implementation speciﬁc mutation operators inspiration new mutation operators index termssoftware testing mutation testing mutation analysis fault analysis mutation operators software testingthe process applying stimuli software judging resulting reactionis common means ensuring software operates correctly designing test cases past experience used estimate potential effectiveness test suite known software faultsmistakes source code use detection faults predict whether test cases effective unknown future faults essentially estimation sensitivity test suite changes source code practice typically lack sufﬁciently large collection faults draw reasonable conclusions instead make use synthetic faults known mutants bpermute order two statements remove static modiﬁer many mutation operators operators vary complexity effect intended reﬂect mistakes developers make mutation testing common technique research practice compare testing techniques suggest areas improvement test design hypothesis test suites detect mutants also detect real faults sensitive small changes code hypothesis hinges idea mutants stand real faults mutants clearly bear little syntactic resemblance real faults tend simple oneline changes code real faults often affect multiple lines code require complex changes ﬁx instead idea mutants substitute real faults based assumption semantic relationship built two hypotheses ﬁrst competent programmer hypothesis suggests many programs close correct minor changes required ﬁx second coupling effect suggests detection many simple mutants enable detection complex fault affecting code however exact nature relationship mutants real faults clear past studies found many factors affect potential correlation mutant fault detection even mutation testing improve test quality immense cost applying mutation large codebase suggests need improvement implementation application practice hypothesize improving effectivenessin terms cost qualityof mutation testing lies better understanding semantic relationship mutants real faults also known coupling particular contrast past studies focus examining different mutation operators degree coupling speciﬁc mutation operators real faults mutation testing technique user generates many mutants automated modiﬁcations original code mutation operators deﬁne types transforma tions code structures example operator may change one arithmetic operation anotherturning b investigate degree coupling executing developer written test suites mutated faulty versions classes multiple opensource java projects based case examples defectsj fault database particular focus trigger teststhe tests detect ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply real fault mutant strongly coupled real fault detected trigger tests tests fail reasonsie exception error mutants weakly coupled may cause additionalor fewertests fail cause tests fail different reasons deﬁned scale rating strength coupling mutant corresponding fault based number failing tests reasons failure scale turn allows us contrast mutation operators ultimately observed mutants detected mutants strongly coupled faults strongly coupled additional tests failing faults least one strongly coupled mutant level coupling individual mutants relatively lowa median score mutation operators median score em asrs isd coi p rv ousm art eoc yield mutants highest median coupling average em asrs mutant strongly substitutes corresponding faults isi jt c oan lv r lowest median scores largely produce mutants resulting compilation errors jt sor aodu p rv orsm art aoru largest percentage mutants detected p rv orsm art yields subtle mutants often strong coupling operators could selectively useful may yield equivalent mutants cause non trigger tests fail sor p rv orref ed aorb aod eoa largest percentage mutants detected nontrigger tests mutants lack sig niﬁcant relationship corresponding faults using past coupling ﬁlter operators could offer cost reductions retaining power mutation testing assess test suite sensitivity experiment threshold yields reduction number mutants retaining diverse subset operators mutants strong coupling understanding semantic relationship could enable im provements mutation testing applied example identifying stronglycoupled operators allows prioritization testing exclusion weaklycoupled operators could lead cost savings ﬁltering noise test suite adequacy estimation addition understanding semantic cou pling enables potential improvements implementation existing mutation operatorseg ensuring mutants compileand may suggest new mutation operators inspire future research also make data availablerandomised testing commonly known fuzzing come critical defence defects vulnerabilities software systems especially systems written c c due unsafe features languages offer webgpu new javascript api allows graphics compute workloads accelerated using clientside gpus avoid potential denial service remote execution attacks arising untrusted web pages issuing malicious workloads enduser gpus critical inbrowser implementation webgpu robust one complex components webgpu implementation compiler translates code written new webgpu shading language wgsl suitable gpu programming language supported users system thus techniques thoroughly testing wgsl compiler quickly ﬁnd eliminate potentially exploitable bugs important separate related google developed swiftshader software renderer used fallback renderer implementations existing webgl api webgpu described successor well webgpu swiftshader allows inbrowser graphics workloads executed end users cpu eg due gpu users system old meet needs webgpu swiftshader conformant implementation vulkan gpu programming model graphics shaders expressed standard portable intermediate representation spirv thus swiftshader incorporates functionality processing optimising spirv programs due use web browsers swiftshader may presented arbitrary malicious graphics shaders report experience google employing variety fuzzing techniques ﬁnd defects compilers wgsl b tools optimising validating spirv used enable webgl webgpu popular browsers chrome edge firefox bugs components major potential negative impact providing necessary background ii paper structured follows deploying coverageguided fuzzing iii explain deployed variety coverageguided fuzzers wgsl spirv processing tools well design various custom mutators wgsl deploying blackbox fuzzing iv written two specialised program generators wgsl allow differen tial validation testing wgsl compilers also deployed clusterfuzz alongside blackbox fuzzer based existing gpu shading language fuzzer summary bugs found v deployment fuzzing clusterfuzz ossfuzz since led security critical issues reported ﬁxed time writing targeted fuzzing tint naga led discovery functional bugs time writing insights vi reﬂect takeaways experience including cases early fuzzing efforts informed design wgsl implementation tint compiler tradeoff beneﬁts domainaware custom mutators effort required create maintain throughout talk current status issues found various fuzzers say time writing refers novemberkirinukiadhconttcojp masaki tajima ntt software innovation center tokyo japan masakitajimazxhconttcojp tanno haruto ntt software innovation center tokyo japan harutotannobzhconttcojp abstractexploratory testing important activity improving software quality despite studies conducted support exploratory testing one reason lack available data exploratory testing activities propose latteart tool support developers recording visualizing managing exploratory testing activities latteart rich user interface variety features support exploratory testing publicly available conducted questionnaire three developers assess whether latteart addresses challenges exploratory testing question naire two developers indicated latteart helps address exploratory testing weaknesses identiﬁed existing literature test activity data recorded latteart easily accessible via rest apis allowing researchers use data facilitate exploratory testing research tool demo available httpsgithubcomlatteartorglatteart index termsexploratory testing sessionbased test manage ment test recording visualization software testing important activity improving soft ware quality industry nist reported industry level impact inadequate software testing infrastructure estimated cost us society approximately billion usd annually software testing typically accounts total development costs many researchers addressed software test automation reduce high cost testing test automation par ticularly effective regression testing widely adopted however many manual testing activities current industrial software development may many skilled developers implement maintain test scripts test automation tests eg screen layout testing user experience testing difﬁcult verify automatically bertolino argues automatic testing still dream software testing research practice testing approaches broadly divided two cat egories scripted exploratory scripted testing follows prescribed process involves design test cases test procedures test execution much existing research scripted testing focuses design generation prioritization automated test cases exploratory testing hand less speciﬁed process uses testers skills ﬁnd bugs testers design execute test simultaneously efﬁciency exploratory testing depends knowledge experience tester bach proposed approach called sessionbased test man agement sbtm facilitates exploratory testing dividing tests time units called test sessions sbtm uses test charters deﬁne scope goals exploration test sessions exploratory testers deﬁnition exploratory testing inherently ambiguous clear distinc tion exploratory testing scripted testing ghazi et al proposed varying degrees exploration fully exploratory fully scripted exemplify ﬁve levels exploration test charter deﬁne scope goals exploration test sessions ghazi et al also identiﬁed strengths weaknesses level exploration open discussion developers shah et al conducted systematic literature review papers books identify strengths weaknesses exploratory testing follows exploratory testing scripted testing complementary preferably used together exploratory testing studies investigate nature efﬁciency process case studies interviews hand several studies support exploratory testing main goal studies improve diversity test cases approach example prompt testers test button operated however compensate weaknesses exploratory testing process consider studies addressed problems exploratory testing eg difﬁculty bug reproduction debrieﬁng monitoring addition lack available datasets activities performed exploratory testing facilitate exploratory testing research solve problem propose platform latteart recording analyzing exploratory testing latteart used test web applications pcs mobile devices automatically record testers operations screenshots web pages performed test session also enables testers enter intentions ﬁndings test session con nect operations latteart visualizes analyzes recorded tests various perspectives support reviewing debrieﬁng tests help develop strategies following tests believe latteart helpful tool developers ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply researchers contributions study follows latteart released open source software oss rich user interface many features support exploratory testing tool enables researchers collect test activity data data used research test analysis recommendation automation tool mitigates problem exploratory testing helps developers conduct exploratory testing summarize shortcomings exploratory testing described existing literature evaluate lattearts contributions overcoming question naire three developers next section presents studies support exploratory testing discuss pros cons exploratory testing section iii clarify lattearts aims section iv describes architecture latteart roles components section v elaborates feature tool section vi presents questionnaire developers evaluation section vii discusses tools solve problem exploratory testing basis results section viii describes limitations latteart section x concludes studysimulationbased testing concerned developing virtual environment captures different components system including hardware software network compo nents using virtual environment test system deployed realworld simulation based testing thus far largely focused discovering individual scenarios tests reveal system failures eg system crashes violations system requirement revealing system failures essential quality assurance task simulators used number important analysis tasks less studied literature paper use simulationbased testing characterizing systems nonrobust behaviours input system reveals nonrobust behaviour making small perturbations input output system changes acceptable passing unacceptable failing vice versa systems cyberphysical network systems sensitive perturbations input caused among factors uncertainty environment evolving systemusage patterns internal computation errors net work degradation systems important able identify test inputs elicit nonrobust behaviours feldt yoo observe existing literature software testing large number system executions typically performed merely produce single test end context simulationbased testing means large number often computeintensive simulations left unused thus wasting time resources recent research proposes use otherwise wasted simulation results building machine learning models generative models models built incrementally test generation algorithm approximate entire part systems input space main usage models guide test generation eg exploring regions likely reveal failures provide additional feedback eg form failure models paper follow line research propose approach combines machine learning adaptive random testing generate value ranges test inputs response system likely exhibit nonrobustness apply approach network trafﬁc shaping system ntss novel case study network domain trafﬁc shaping advanced technique improve quality transmission voice video types streaming trafﬁc conﬁgure ntss way ensures high quality network transmission maximizing bandwidth utilization need identify input ranges make ntss nonrobust collaboration industry partner rabbitrun tech nologies httpswwwrabbitrun develop simulation environment test ntss present nonrobustness analysis traffic shaping enrich method ap proximate input ranges likely lead nonrobust ntss behaviours enrich implements adaptive random testing algorithm based ntss simulator test cases gen erated adaptive random testing used train machine learning regression tree areas input search space include systems nonrobust behaviour inferred areas passed adaptive testing algorithm focus test generation inferred areas since areas likely include inputs make system ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply nonrobust iterative test generation regression tree model reﬁnement continues computational budget exhausted ﬁnal regression tree used infer value ranges ntss inputs lead nonrobustness regression tree model generated enrich ﬁrst iteration trained evenly distributed samples entire search space thus yielding explorative global view contrast models generated later iterations become focused inputs likely make system nonrobust models provide exploitative view desired regions search space difﬁcult accurately approxi mate whole search space relying explorative views shown earlier research gradual move explorative exploitative view adopted enrich effective inferring promising areas search space ie nonrobust regions context work gradual reﬁnement evaluate enrich ntss setup recommended rabbitrun compare enrich standard baseline based random testing baseline infers nonrobust test inputs using regression tree model built based samples uniformly selected search space ie explorative model without exploitative model results show enrich signiﬁcantly performs baseline generating characterizing non robust test inputs ntss particular enrich able identify nonrobust test inputs precision recall yielding signiﬁcantly higher overall accuracy baseline addition results show statistically signiﬁcant difference test results obtained simulator results obtained executing tests physical hardware testbed contributions make following contributions introduce problem capturing nonrobust test inputs network trafﬁcshaping systems section ii build industrystrength simulation environment ntss section iii detailed instructions building simulation environment publicly available present enrich approach automatically infer input ranges likely lead nonrobust ntss behaviours section iv evaluate accuracy enrich ntss simulator section v experimental results publicly available reﬂect lessons learned collaboration rabbitrun technologies section vii structure section ii motivates nonrobustness analysis ntss section iii describes ntss simulator section iv presents approach characterizing nonrobust test inputs section v describes evaluation section vi compares related work section vii outlines lessons learned section viii concludes papere diﬃcult exercise observe combined appropriate test generation strategy also apply approach two case studies defectsj framework known bugs aﬀect causal behaviour results case studies suggest approach useful catching bugs aﬀecting causal structure also alerting user inaccuracies speciﬁcation metamorphic testing provides approach reasoning correctness systems output terms changes inputs way single metamorphic rela tionship used succinctly summarise expected results potentially inﬁnite range inputs opposed conventional approach writing test oracles check results speciﬁc individual inputs result metamorphic testing successfully applied various classes systems traditionally perceived particularly hard test machine learning systems compilers one barrier widespread application metamorphic testing diﬃculty formulating metamorphic relation ships although several advances semiautomatic metamorphic relation construction made exist ing approaches signiﬁcant limitations techniques reverseengineer metamorphic relations executions risk reverseengineering faulty relations underlying code faulty approaches restricted speciﬁc domains ultimately construction metamorphic relations diﬃcult task technique generalisable reliable instead burden task typically falls experienced tester domain expert must rely upon ingenuity intuition approach proposed paper based observation metamorphic testing inherently causal activity transformation applied input order establish causal eﬀect output viewed perspective several powerful approaches modelling reasoning causality become particularly widespread areas epidemiology authors however aware eﬀorts use approaches systematically generate metamorphic tests paper propose causal modelbased approach generation metamorphic relations test cases approach centred around causal directed acyclic graphs dags wellestablished extremely simple graph ical model used extensively model causal relationships wide range disciplines show causal dags used model expected causal relationships inputs outputs software system used turn automatically generate metamorphic relations test cases series controlled experiments realworld case studies evaluate ability approach detect speciﬁc class bugs modify causal structure programundertest appear forms software overall make following contributions present approach metamorphic testing uses causal graphs automatically generate metamorphic relations source followup test cases perform controlled experiment analyse ability approach detect structural causal bugs increasingly challenging conditions apply technique realworld software defectsj framework known structural causal bugs remainder paper structured follows sec tion ii introduces motivating example provides necessary background paper section iii deﬁnes causal bugs provides evidence bugs common software engineering section iv describes process creating metamorphic relations causal dags section v presents empirical evaluation technique discussing results section vi demonstrating application two realworld case studies section vsoftware systems grown increasingly complex recent years need new tools test robustness emerged address issue miller et al introduced fuzz testing method automatically generates test inputs one popular approach fuzz testing grammar fuzzing inputs generated based given grammar grammar fuzzing efﬁcient fuzzing technique however requires input grammar often available method overcome limitation grammar mining tries extract grammars inputs software systems recent ideas existing grammar mining systems shown promising results still come limitations inputs addition mera showed capable extracting semantic rules heerden et al steinhofel zeller pointed grammars used grammar fuzzing often lack se mantic rules contextual constraints example semantic information like variable declared usage xml open close tag identiﬁer would allow generating precise inputs limitation also identiﬁed gopinath et al like valid start therefore thesis aims develop methods mining grammars software systems enriching grammar semantic rules contextual constraints ultimately enabling efﬁcient fuzz testing approach following use concolic execution extracting semantic information target program first results available publishedstatic program analysis used wide variety ap plications optimization security analysis tools many techniques exist many rely call graph ie graph function called call site call graphs often built using ﬁxedpoint algorithm start code known called eg main method java add code calls continues code added call graph obtained many analyses built top framework applications complicate analysis least two ways comprising relevant code intractable analysis muddying notion program actually many modern frameworks use dynamic features eg constructing string using class name java unless analysis able precisely interpret operations construct string able understand class used hence able determine relevant code furthermore many frameworks use code multiple languages eg jni calls c code java analysis frameworks handle one language code determined often much analyzed scalable fashion thus static analysis tools model frameworks rather analyze modern frameworks also complicate notion pro gram many modern programs effect clients framework eg think servlet installed tomcat web server programs entry points expect called framework ﬁnding entry points depends framework sometimes spring framework expects user code annotated speciﬁc ways cause framework call sometimes speciﬁc interfaces must implemented user code signal speciﬁc code called framework often user code makes call framework framework calls back user code similar way thus program becomes collection pieces knitted together framework prominent example framework android common approach handling kind framework build custom model attempts expose relevant semantics framework respect program android example model add entry points methods implement appropriate interfaces neverending since many frameworks framework keeps changing result model constant struggle model semantics thus analysis easily miss many real issues mechanisms averroes developed tackle situation dealing java libraries avoiding much manual modeling library code averroes analyzes original library create coarse model attempts approximate library behavior potentially results conservative analysis compromises needed look framework effective analyses mechanisms designed support precision required security analysis especially need ﬂowsensitivity ﬁeldsensitivity frameworks usually provide rich library functionalities different libraries unlike libraries frameworks commonly use inversion control principle averroes fails handle involves framework main program support security analyses context handling modern java frameworks present gencg extends averroes improvements model model execution order needed ﬂowsensitivity time restricting model give analysis completeness anal focus code ysis issues evaluation two realworld benchmark suitestaintbench fdroid android taint analysis shows call graphs using model generated gencg cover signiﬁcant code times result greatly enhances recall true analysis results client taint analysis android namely flowdroid compared flowdroids hardcoded model likely result ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply class mainactivity extends activity msg msg new msg public void onstart mainactivity new mainactivity location loc lmgetlastknownlocationnetwork source msgsetcontentloctostring public void onpause superonpause intent intent new intentthis taskserviceclass intentputextradata thismsg startserviceintent class taskservice extends service looperthread looperthread handler handler public int onstartcommandintent intent int ﬂags int startid handler looperthreadhandler msg msg intentgetserializableextradata message msg handlerobtainmessage handlersendmessagemsg return superonstartcommandintent ﬂags startid class looperthread extends thread looper looper context context handler handler public void run handler new pushmessagehandlercontext looper class pushmessagehandler extends handler string url httpupmsghtm public void handlemessagemessage msg listnamevaluepair pars new arraylist parsaddnew basicnamevaluepairloc new gsontojsonmsgobj httppostsetentitynew urlencodedformentitypars utf httpclientexecutehttppost sink listing motivating example time approach introduce false positives demonstrate gencgs applicability frameworks experiment spring framework shows effectiveness evaluating micro benchmark suite spring applications contributed us along paper artifacts publicly available https doiorgzenodorandom propertybased testing rpbt popular tech nique ﬁnding bugs using executable testing properties practical limitation rpbt need random data generators used instantiate testing proper ties writing highlytuned generators take several thou sand personhours trial error luckily exist several approaches automatically synthesize random data generators extracting static information codebase eg data type deﬁnitions application public interfaces apis approaches however unable synthesize generators capable producing data satisfying complex invariants easily derivable codebase generating random valid programs test compilers clear example limitation developers forced write specialized generators hand coverageguided propertybased testing cgpt technique borrows ideas fuzzing community generate highlystructured values still using auto matically derived generators cgpt keeps queues inter esting previously executed test cases transformed using structurepreserving mutations produce new ones intuitively mutating existing interesting test case likely produce new interesting test case generating work funded swedish foundation strategic research ssf project octopi ref rit websec ref rit well swedish research agency vetenskapsradet new one scratch moreover unlike generic bit level mutators often used fuzzing community structurepreserving mutations speciﬁed data type level effectively produce syntactically valid mutants approach shown effective fuzzing systems accepting structurally complex inputs notably cgpt uses data type information inputs test ing properties derive specialized structurepreserving muta tors directly without need external grammars making stronglytyped programming languages ideal match technique addition cgpt relies execution traces distinguish interesting test cases technique popularized coverageguided fuzzers like afl test cases interesting therefore worth mutating exercise new parts code system test work establish several aspects seminal cgpt approach lampropoulos et al leave room improvement see ii particular done carefully automatically derived structurepreserving mutators come shallow unlikely transform deep test cases superﬁcially queuing mechanism cause delays interesting test cases enqueued frequently way prioritize heuristic used assign mutation budget interesting test case often referred power schedule requires ﬁne tuning hard generalize overcoming obstacles important make cgpt suitable testing realworld software tackle limitations introduce mutagen cgpt framework applies mutations exhaustively see iii given interesting test case tool forces ev ery structurepreserving mutation applied evaluated exactly two main advantages firstly every subexpression input test case mutated basis ensuring deep transformations omitted due randomness moreover computing mutations exhaus tively eliminates need heuristic power schedule internally mutagen distinguishes two kinds mutations one hand deterministic pure mutations encode trans formations yield single mutated test case obtained swapping data constructors around well rearranging returning subexpressions hand nondeterministic random mutations used represent transformations large enumeration types mechanism let us selectively ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply escape scalability issues exhaustiveness yielding random generator replaces speciﬁc subexpression input test case randomly generated one generator later sampled relatively small number times way mutagen avoids instance mutating every number inside test case every number range mutagens testing loop incorporates two novel heuristics help ﬁnding bugs reliably iv ﬁrst place tool uses lastinﬁrstout lifo scheduling priority enqueueing interesting test cases mutation way interesting test cases discover larger parts untested code given higher priority moreover lifo scheduling allows testing loop jump back forth enqueued test cases soon new interesting ones become available eliminating potential delays mutation queues grow often shrink second heuristic controls number test cases sampled random mutations monitoring often generate interesting test cases whenever frequency stalls mutagen resets testing loop increases effort put sampling random mutations way tool automat ically adjusts parameter ﬂy validated ideas two different ways ﬁrst compared mutagen fuzzchick reference cgpt implementation lampropoulos et al existing cases studies described original work case studies focus ﬁnding counterexamples buggy variations two informationflow control ifc machines different complexity results vi indicate bugs relatively easy ﬁnd mutagen reliably ﬁnd faster fuzzchick hand bugs harder ﬁnd tool outperforms fuzzchick terms failure rate cost possibly needing time ﬁnd notably mutagen capable ﬁnding bugs fuzzchick able ﬁnd evaluation original one additionally compared mutagen quickcheck widely used rpbt tool haskell existing webassembly engine implementation industrial strength mutagen capable reliably ﬁnding planted bugs validator interpreter well pre viously unknown ones moreover case study lets us eval uate performance versus overhead tool custom code instrumentation mechanism eval uation indicates testing mutants exhaustively together heuristics escape scalability issues appealing technique ﬁnding bugs reliably without sacriﬁcing speed additonally present threats validity vii dis cuss related work viii ﬁnally conclude ixmutation testing white box testing method aims inject artiﬁcial changes based real faults order evaluate test suites capability reveal faults mutation testing extensively studied used traditional software engineering assess quality test suites fundamental hypothesis mutation testing coupling effect hypothesis posits complex mutants coupled simple mutants way set test cases detects simple mutants program detect large percentage complex mutants uncovering unkilled complex mutants interest one way generating complex mutants combine simple mutants called first order mutations fom together concept higher order mutations hom introduced jia et al established testing techniques concepts could useful deep learning systems effort increase reliability since systems notoriously hard test peculiar nature paradigm equal contribution differences deep learningbased systems tradi tional software systems recently researchers started proposing mutation testing frameworks tailored deep learningbased systems particular supervised learning assess quality test dataset revealing faults yet supervised learning subparadigm machine learning deep reinforcement learning rl one main subparadigms wide range applications increasingly adopted practice rl differs deeply supervised learning super vised learning model learns training dataset order generalize new data input distribution rl based idea training agent using interaction environment feedback system instance robot agent evolving room environment goal go b traps way previ ously introduced frameworks might present several limitations applied rl instance mutation operators deﬁned supervised learning obtain mutant models might apply rl parallel best knowledge research work tackled mutation testing rl proposing fault detection approach based manual crafting relevant environments particular introduced idea traditional test cases used mutation testing applied traditional software systems could translated notion test environments rl however study limited one type rl algorithm explore real faultbased operators potential usefulness combining existing operators form hom could prove useful assess test environments capacity ﬁnd subtle faults rl systems paper propose framework rlmutation mu tation testing deep rl programs leveraging hom adapted rl deﬁned mutation operators rl motivated existing taxonomized faults analyzed fared different rl environments algorithms using comparing number mutation killing deﬁnitions adapted previous works order leverage hom power highlight complex faults adapt existing work hom rl task speciﬁcity namely conceive simple heuristic tailored rl problem systematically generate test environments order obtain test cases assess hom usefulness thus aim provide insights mutation testing could applied rl ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply acknowledging existing differences supervised learning contribution proposed rl framework composed following mutation operators based real taxono mized faults comparison impact mutation killing deﬁnition design fom killed heuristic generate relevant test environments study fom hom remainder paper structured follows section ii gives relevant background knowledge muta tion testing hom rl section iii presents mutation operators introduced well procedure determine generate relevant hom using mutation testing rl section iv reports experiments results section v discusses threats validity work section vi reviews related literature section vii concludes papermotivation different semiautomatic debugging fault localization techniques proposed aid programmer activities research focus two important areas namely spectrumbased fault localization sbfl program slicing ps two approaches fundamentally different program slicing based structure syntactic relationship elements spectrumbased fault localization statistical approach relies test execution statistics sbfl uses execution information program locate faulty code element takes program spectra input two components code coverage matrix error vector code element assigned suspiciousness value based many failing test cases executing compared passing ones since perfect formula compute suspiciousness ranking results approximate efﬁciency difﬁcult predict hand using ps compute subset program program slice might inﬂuence program point interest case point failure observed numerous program slicing techniques available many different applications however debugging one important ones particular dynamic slicing ds often advised technique suitable debugging fault localization computes result speciﬁc program executions opposed static slicing ss possible executions considered could different ways combining two ap proaches using program slice enhance sbfl rank list using highly suspicious elements parametrise program slicing also vast set concrete algorithms choose areas evident combination would work best examples existing methods following reis et al used sbfl ds increase diagnostic accuracy reducing suspiciousness components often failed involved passed tests related fault according ds soremekun et al examined hybrid approach found programmer ﬁrst checks suspicious elements uses ds average lines code need examined reduced alves et al combined ds sbfl reduce cost inspection without increasing computational cost achieve authors used additional analysis information remove nonfaulty statements sbfl ranking shu et al improved sbfl failed execution slices prioritized using sbfl ranking main motivation work presented paper ﬁnd systematic overview possibilities combining statistical fault localization program slicing clear particular approach performs best practical situations also since ultimate application debugging target users programmers working integrated development environments would important understand hybrid methods could best used practice ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions applysoftware service system deﬁnes input space cannot exhaustively explored combinatorial testing widespread approach select test cases spaces characterized set parameters domains parameters partitioned classes values forming choices parameter combinatorial testing covers tuples choices coming different parameters order exercise interaction empirical studies shown interaction bugs involve combination parameters hence widely used combinatorial testing strategy pairwise testing pt tuples simply pairs checking way interactions pt algorithms classically consider ﬂat set parameters number ﬁxed deﬁnition ﬁt well applications process structured data like xml json documents input space consists data elements various types embedded elements multiplicity cannot easily brought back ﬂat set interacting parameters example let us assume xml input describes population person elements age hobby attributes structure multiplicity cannot ignored since interactions age hobby may covered context one person instance different ones moreover various population sizes cover various possible shapes persons eg person may children complicate things shape numerical content data may satisfy semantic constraints instance young persons cannot children work revisits accommodate hierarchical data structures constraints contributions following pt concepts formalize pt problem input data trees labeled element names deﬁnitions choices pairs consider multiplicity elements access paths common ancestors coverage checks expressed xpath queries data trees best knowledge ﬁrst pt formalization attempt context rich inputs like xml documents demonstrate implementation formalization top recent tool taf taf mixes random sampling constraint solving generate instances xmlbased data models propose two pt algo rithms leverage tool unguided taf freely produces data instances monitor coverage progress guided insert pair coverage constraints data models drive taf also study greedy variants algorithms seeking cover greatest number new pairs iteration algorithms applied two examples data models constraints scene agricultural tax robot management system population taxpayers section ii discusses related work section iii presents formalization pt problem successively revisiting concepts test parameters choices pairs section iv introduces implementation top taf section v gives experimental results two case studies section vi concludes paper future directionscontinuous fuzzing running fuzzers periodically gen erate new test inputs guard project regression bugs along series program changes ossfuzz demonstrated effectiveness continuous fuzzing detecting bugs open source projects continuous fuzzing becoming increasingly popular projects hosting fully automated contin uous integration pipelines cloud greybox fuzzers advancing better support trend regression fuzzing techniques utilize information program changes quickly discover recently introduced fail ures zhu bohme proposes changeaware power scheduling scheme put fuzzing effort code region recently changed frequently updated yoo et al presents technique reuse seed corpus previous version fuzzing subsequent versions based program change information selectively exploring changed behaviors regression fuzzing quickly discover regression bugs save computation effort retesting unchanged behaviors regression fuzzing promising direction enhancing continuous fuzzing efficacy investigations ex pected follow improve regression fuzzing techniques however existing fuzzing benchmarks suitable evaluating regression fuzzing techniques study artifacts artificially constructed based bug fix information ie patches reproducing actual commits introduce bugs target projects paper presents bugoss collection realworld regression bugs package information exper imenting regression fuzzing techniques help researchers reproduce realistic project context continuous fuzzing performs buginducing commit artifact bugoss indicates exact commit regression bug introduced version history provide ground truth condition check whether failure induced regression bug coexisting faults systematically extracted pieces information ossfuzz issue tracker target project repositories avoid uncertainty section ii currently artifacts cc programs regis tered bugoss benchmark understand charac teristics conducted experiments two generalpurpose fuzzers two regression fuzzing techniques section iv experiment results found artifacts encompass various cases realworld regression bugs best authors knowledge bugoss first bench mark actual buginducing commits realworld projects continuous fuzzing studying regression fuzzing techniques believe bugoss offers researchers useful basis empirical investigation regression fuzzing techniques publicly available following site httpsgithubcomarisehandongbugossmany aspects daily lives automated software however far faultless software bugs result dangerous situations including death result var ious software fault localization techniques spectrum based fault localization sbfl proposed last decades sbfl calculates likelihood program element faulty based program spectra collected executing test cases results sbfl hand yet widely used industry due number challenges issues sbfl code elements ranked least sus picious based suspicion scores basic approach execution information element used calculating scores result sorts information types statements relationships statements many times statement executed etc disregarded lowers sbfls effectiveness therefore many studies involved types information improve effectiveness paper improve effectiveness sbfl involving static information code element sbfl process give importance code elements include mathematical operators compared types elements eg declaration selection iteration jump function return function call intuition elements error prone due computations include critical parts algorithm kinds statements generally treated simple means probability mistake lower proposed approach applicable sbfl formula without requiring modifications structures score values adjusted rankings produced performed limited experimental study implement ing method python programs used subject system seeded faults results show proposed approach achieved better performance average ranking positions topn measurements compared underlying sbfl formulas namely average ranks dropped around number highest rank positions doubled faults ranked top worst casereliance realworld applications smart systems based deep neural networks dnns constant rise several years include applications safety critical systems like autonomous driving healthcare raises concerns regarding reliable acceptable performance dnns diverse range input scenarios including ones pertaining consistent performance dnns trained longtail distribution ie training datasets significant portion total inputs belonging head classes small subset inputs belonging tail classes concerns surrounding longtail distribution ill founded numerous available datasets fact comprise longtail distribution mitbih arrhythmia dataset contains significant proportion normal ecg samples opposed ecg samples indicating arrhythmia imdb wiki dataset comprises significant proportion caucasian faces wafer map training dataset comprises proportion faultfree wafers opposed faulty wafers discrepancy number inputs across different output classes always surprising since tail classes often present rare events realworld also surprising dnns trained long tail distribution learn patterns head classes better tail classes due availability ample input samples also observed networks also delineate robustness bias influence noise ie network likely correctly classify even noisy inputs head classes robustness tail classes noise negligible orthogonally sensitivity input nodes also found vary variation comes handy determining relevant input nodes designated task trained dnn may also pose concern applications revelation sensitive attributes nodes may lead privacy infringement however another aspect concern dnns inadvertently linked indicated ie robustness bias individual input nodes remains unrecognized existing literature work deals node bias indicating stealthy existence non triviality understanding causes summarize novel contributions work follows defining concept node robustness bias highlighting link robustness bias node sensitivity node bias identifying existence node bias empirically network trained realworld analyzing leukemia dataset discussing severity node bias respect long tail distribution training dataset elucidating open challenges pertaining node bias trained dnnse statements proposed tool supports different important features fault localization supporting sbfl formulas different tiebreaking methods showing code elements different colors ranging suspicious red suspicious green based suspicious scores allowing user define hisher formula etc using tool could help developers efficiently find faults programs index termsdebugging fault localization python sflaas programs play important role daytoday activities nonetheless errors faults still exist critical may lead serious consequences thus several software fault localization approaches implemented spectrumbased fault localization sbfl sbfl level suspiciousness faulty program entity computed depending program spectra acquired performing set test cases however widespread industry sector issues one issues sbfl tools focus cc java programs therefore lacks support developers debug software popular programming languages python paper implement software tool named sflaas service enable software fault localization process used anywhere anytime tool useful python developers easily analyze software generating data produce list suspicious elements runtime mark element suspicious element examined developer top list bottom suspicious element least one tool cloudbased service means python program needs uploaded server results observed website enables quick experimentation sbfl method instant debugging simple cases also used effectively educationlarge corpus academic literature online blog articles shows issue test ﬂakiness regarded major concern software testing community discussion brought forth several approaches aiming mitigate problem visualizing behavior ﬂaky tests quantifying impact quarantining well automatically debugging reducing even ﬁxing ﬂakiness common methods rely availability effective techniques accurately detect tests ﬂaky therefore displayed dashboard trigger alarm intensively analyzed determining given test failure caused ﬂakiness might complicated task skilled developer manual inspection becomes infeasible larger projects make hundreds changes per day therefore run thousands regression tests hence need detecting ﬂaky tests automatically address demand researchers proposed many ﬂakiness detection approaches found difﬁcult implement industrial setting since rely code instrumentation always implementable demand multiple test reruns computationally demanding require languagespeciﬁc artifacts observation underlined recent study found adoption rates automated ﬂakiness detection techniques among practitioners poor despite limitations existing approaches exists information widely easily available industrial contexts hypothesize sufﬁcient order build predictive models detect test ﬂakiness particular data includes tests outcomes durations existing test executions test history well code churn information number changed ﬁles current pull request evolution code using largescale industrial software project subject evaluation aim assess information indeed applied effectively detecting ﬂaky tests sample test data case study software project build evaluate different feature combinations multiple established binary classiﬁers detail key contributions compilation implementation widely easily available candidate features ﬂakiness detection data set ﬂaky nonﬂaky tests derived real industrial software product detailed evaluation ﬂakiness detection capabilities information data set results suggest evolution code history tests powerful predictors test ﬂakiness best performing model achieving fscore using features weighted ﬂip rate number source code changes last days number changed ﬁles current pull request comparing different weighting algorithms ﬂip rate found stronger decaying functions yield better results examining different feature combinations found code churn information plays vital role models without predictive performance dropped fscore overall study demonstrates common code evolution test history data effectively applied detect ﬂakiness therefore offer compelling alternative projects cannot meet requirements existing ﬂakiness detection techniques ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions applyyadavtuwienacat abstractmutation testing established software quality assurance technique assessment test suites wellsuited estimate general faultrevealing capability test suite practical informative software test must validated speciﬁc requirements often case embedded software software typically validated rigorouslyspeciﬁed safety properties scenario mutant relevant impact satisfaction tested properties ii mutant meaningfullykilled respect property causes violation property address limitations mutation testing introduce propertybased mutation testing method assessing capability test suite exercise software respect given property evaluate propertybased mutation testing framework simulink models safetycritical cyberphysical systems cps automotive avionic domains demonstrate property based mutation testing informative regular mutation testing results open new perspectives mutation testing test case generation cps index termscyberphysical systems mutation testing sig nal temporal logic stl simulink models software testing software pivotal role safetycritical applications autonomous vehicles medical devices inadequate soft ware quality assurance may result potentially catastrophic system failures thus important thoroughly test software checking violate critical properties mutation testing mt wellestablished technique measure adequacy test suite wrt fault model mt ﬁrst injects artiﬁcial defects software undertest measures thoroughness test suite percentage injected faults test suite reveal injection performed mutation operators modify software according welldeﬁned patterns resulting modiﬁed program called mutant test case kills mutant execution causes observable differences behavior original mutated programs ratio killed mutants wrt mutants equivalent original program known mutation score ideally test suite reach mutation score equal one mt effective test suite assessed wide set faults spread software loses effectiveness purpose test suite validate software speciﬁc requirements particularly true embedded software domain software must often validated rigorouslydeﬁned safety properties example atcs automatic transmission controller system used experimental evaluation annotated several safety properties expressed signal temporal logic stl test cases designed validate software properties applying mutation testing assess capability test suite thoroughly exercise software wrt given prop erty two challenges take consideration relevance mutants relevance executions kill mutants relevance mutants wrt tested property mutants relevant assess thoroughness test suite property fact mutants whose effects propagate way ultimately causes property violation relevant mutant impact property shall also contribute measuring adequacy test suite property regular mt distinguish mutants hence consider difference computing mutation score relevance execution kills mutant producing different outputs original mutated programs insufﬁcient kill mutant test suite assessed property fact test thoroughly exercising software wrt property difference two outputs severe relevant enough cause violation property consideration otherwise test generating differences marginal wrt testing objective instance evaluation assessed test cases atcs property requires engine speed vehicle speed remain certain thresholds several tests succeeded exercising mutant transmission component causing differences outputs failed produce outputs violate properties clear inadequacy test suite situation visually illus trated fig top test generating differences engine vehicle speeds without exceeding threshold mutant would counted killed according regular mutation testing although test make software violate property practice fault would present original model test would reveal also exempliﬁes mutations could easily killed according regular mutation testing dataﬂow models components activated every computation values easily propagate blocks model however ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply propagated values often result minor nonsigniﬁcant output differences killing mutants taking tested properties consideration deﬁnitely harder challenge instance fig bottom shows case test reveal mutant violating tested properties obtained experiments output vehicle speed output engine speed h p e e p e l c h e v h p e e p e l c h e v p r e e p e n g n e original model mutant threshold time seconds time seconds output vehicle speed output engine speed p r e e p e n g n e time seconds time seconds fig output plots original mutated models atcs top test case satisfying property mutant bottom test case violating property mutant portion output trace vehicle speed responsible property violation highlighted paper address challenges deﬁning notion propertybased mutation testing pbmt assess test suites properties speciﬁcations end revise key notions mutation testing measure effectiveness test suites capability exercise software property also deﬁne searchbased test generation strategy simulink models effectively automatically identify relevant mutants could killed meaningful executions set injected mutants provide empirical evidence pbmt informative mt assess thoroughness test suites considering two benchmarks domain safetycritical cps requirements expressed stl formalism summary paper makes following contributions introduce novel notion propertybased muta tion testing testing software properties deﬁne searchbased strategy automatically iden tify mutants contribute pbmt experiments report empirical results simulink models demon strating pbmt informative regular mt software tested properties make tools experimental data publicly available reproduction ease followup research httpsgitlabcomdrishtiyadavmt paper organization section ii presents overview regular mutation testing section iii presents propertybased mutation testing proposed approach section iv describes testing cps simulink models stl speciﬁcations sec tion v presents evaluation two safetycritical industrial benchmarks section vi discusses threats validity sec tion vii describes lessons learned section viii presents related work section ix concludes paperbackground frequent release functional product code heavily reliant automated regression testing largescale internet software companies common number test cases executed daily rack quickly high usage paramount support qa engineers creation complex test infrastructure test frameworks developed maintained tandem frequent changes product code ensure smooth functioning continuous integration continuous delivery pipeline may sometimes complex product code shipped numerous advancements made research industry sectors support software engineers de veloper experience qas may beneﬁt tools daily work expectations qas differs developers enough make worthwhile discussing qa speciﬁc productivity metrics currently insufﬁcient research conducted tools created catered speciﬁcally qa contributes perception software testing secondrate software development even though maturity testing framework directly impacts production speed efﬁciency corresponding author similar production metrics support software engineers developer experience qas beneﬁt observability system test automation framework help chart evolution test framework improve towards test automation maturity stateof theart test automation frameworks provide observability rigid limited offering analyses tests written within framework make little mention impact regression testing broader software devel opment lifecycle good observability framework able provide reliable metrics solely test automation development execution also impact test automation speed quality software development also ﬂexible enough accommodate qas selection best test tools product time view fastchanging nature technology present qex monitoring framework integrates common testing data sources obtaining high observability test development suitable largescale enterprise contexts supports qa engineers developer experience providing comprehensive reliable timely feedback testing activity throughout test automation devel opment life cycle paper explain design qex framework describe opensource implementation qex currently used company providing reader handles implement customise suit needs finally provide evaluation framework discuss possible advancements implementationch gunel jahangirova department informatics kings college london london uk guneljahangirovakclacuk paolo tonella software institute università della svizzera italiana usi lugano switzerland paolotonellausich shin yoo school computing kaist daejeon republic korea shinyookaistackr abstractas deep neural networks dnns rapidly adopted within large software systems software developers increasingly required design train deploy models systems develop consequently testing improving robustness models received lot attention lately however relatively little effort made address difﬁculties developers experience designing training models evaluation model shows poor performance initial training developer change survey evaluate existing stateoftheart techniques used repair model performance using benchmark realworld mistakes developers made designing dnn models artiﬁcial faulty models generated mutating model code empirical evaluation shows random baseline comparable sometimes outperforms existing stateof theart techniques however larger complicated models repair techniques fail ﬁnd ﬁxes ﬁndings call research develop sophisticated techniques deep learning repair index termsdeep learning real faults program repair hyperparameter tuning deep neural networks dnns rapidly adopted large software systems due signiﬁcant advances performance across multiple domains image speech recognition machine translation autonomous driving especially application domains medical imaging autonomous driving safetycritical ﬁndings failureinducing inputs adversarial examples posed serious threats resulting signiﬁcant efforts test improve robustness dnn models considering proposed ways improve model performance robustness attention directed training dataset looking effective methods augment order address discovered deﬁciencies however model may exhibit poor predictive performance eg high prediction errors issues affecting model structure training process training data relatively little work done repair model structure improve training process compared training model augmented dataset following refer model architecture faults broad meaning mistakes made developers specifying model training process source code examples faults include choice inappropriate activation function layer dnn large value learning rate optimiser mistakes critical impacts models predictive performance yet also remain easy make software engineers necessarily experts deep learning importantly mistakes often easy ﬁx manually developers eg due lack expertise stochastic nature dnn models cost training evaluating candidate patches paper assesses existing dnn improvement techniques proposed within software engineering se machine learning ml research communities particular former aim explicitly detecting eliminating problematic symptoms observed training vanishing gradients dying relu latter aim optimising models hyperparameters neither directly addresses issue model architecture faults made developers nonetheless take input underperforming model produce output repair actions ﬁx architectural faults affecting model two families techniques large overlap terms model architecture faults address consider empirical assessment speciﬁcally focus empirical evaluation auto trainer representative dnn repair tool recently presented ﬂagship software engineering conference icse hebo bohb represent stateoftheart among hyperparameter optimisation hpo techniques developed machine learning community latter belong bayesian optimisation family shown outperform alternative approaches eg searchbased sanity check include random search baseline study use collection realworld artiﬁcial model ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply architecture faults evaluate repair techniques real world model architecture faults manually curated fault benchmark made available cao et al turn collected github issues stackoverﬂow questions dnn model underperformance artiﬁcial model architecture faults created applying source level mutation operators designed based taxonomy realworld faults consider model architecture fault ﬁxed improvement model performance measured across multiple runs statistically signiﬁcant models study include image classiﬁers mnist cifar text classiﬁer reuters eye gaze direction predictors based unityeyes simulator results show existing techniques capable improving models architecture faults ample room improvement surprisingly random baseline generally performs competitively sophisticated repair techniques also random hpo techniques signiﬁcantly outperform autotrainer however none studied techniques shows good performance larger complex models analysis simulates different time budgets technique reveals random hpo techniques tend perform better larger budgets allowed autotrainer beneﬁt larger budgets lastly complexity analysis generated patches shows techniques tend produce complex patches compared humangenerated ground truth ones ie redundant changes compared ground truth patches contributions paper follows present wide empirical evaluation existing state oftheart techniques automated repair dnn model architecture faults provide carefully curated benchmark repairable model architecture faults various dnn benchmark datasets tasks includes realworld faults well artiﬁcial mutations rest paper organised follows section ii formulates problem automatically repairing dnn ar chitecture faults introduces techniques evaluate section iii describes fault benchmark use empirical evaluation section iv describes design empirical study results presented section v section vi discusses ﬁndings obtained empirical evaluation followed threats validity section vii sec tion viii presents related work section ix concludessoftware application collection multiple systems coupled together achieve goals whole facilitates incremental modular development well reuse external libraries however order component tested must decoupled others solution problem use test doubles within unit tests external components replaced skele tal implementations called mocks since mock substitutes interactions component actual component bypassed instead behavior mock declared stubs method triggered certain input mock canned response returned mocks stubs allow focus verifying correctness component test fewer side effects faster test executions quicker fault localization however using trivial writing unit test developers must manually decide components may mocked also stubbed mocks generated automatically search based algo rithms symbolic execution may correspond real production behavior key insight using data collected production generate tests mocks ensures behavior triggered actual users tested even complement developerwritten test suite propose rick tool observes executing applications collects data goal automatically generating tests use mocks stubbing behavior accordance production invocations furthermore tests generated rick contain mockbased oracles derived data collected production verify distinct aspects invocation target method interactions external components demonstration presents overview rick companion video illustrates rick action open source routing application called graphhopper class classundertest exttypeone extfield int methodundertestint exttypetwo extparam int x extfieldmockablemethodonea int extparammockablemethodtwob return listing mut two mockable method calls identiﬁed target test generation rickaccording statista google play ofﬁcial android app market possesses million apps offer plethora functionalities android users despite fact android app markets growing app categories enriching years apps similar functionalities existing popular ones still emerging example time paper writing searched keyword calculator new ﬁlter appbrain among resulting apps published recent month according app age attributes apps diverse appearances language preferences privacy policies core functionalities typically instance mobile browsers must able visit website url navigate different web pages regardless color schemes widget shapes moreover core functionalities usually triggered via particular user interaction patterns eg enter url top bar yepang liu corresponding author browser visit new web page reusing common interaction patterns speciﬁc functionalities good practice reducing users learning costs newly installed apps android developers usually write gui test scripts using test automation frameworks like uiautomator quality assurance however newly created app developing maintaining test suite laborintensive expensive reduce cost testing apps recent studies proposed techniques reusing existing test suites apps similar functionalities approach called test reuse however existing test reuse techniques suffer major limitation require test suite reference app input usually unavailable large commercial closedsource apps prevents practical use migrating android gui tests test reuse despite abundant research gui test automation manually performing gui testing still widely adopted android developers given automated test scripts hard maintain recordandreplay becomes good alternative facilitate gui testing recordand replay human testers need write test code instead manually perform user events test device events recorded test cases replayed regression testing purposes insight addition regression testing recorded test cases also reused replayed test apps similar functionalities call scenario crossapp recordandreplay test cases recorded source app transferred exercise another target app existing recordandreplay approaches android plat form mostly concern stability compatibility gui test cases across different android devices tools cannot directly adapted crossapp scenario two technical challenges crossapp recordandreplay first source app target app created different developers ways interaction typically identical usage scenario required user events different hence crossapp recordandreplay able map one event source app multiple events target app vice versa second unlike test reuse identiﬁes source event widgets unique textual locators ie resourceid attributes test scripts raw recorded events typically coordinatebased since texts essential semantic mapping widgets lacking accurate textual indicators functionalities ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply textual increase difﬁculty identifying appropriate target widgets propose rida tool recordandreplay different android apps rida addresses aforementioned challenges following ways achieve onetomany manyto one event mapping rida ﬁrst identiﬁes source widgets selfreplaying extracts widgets semantic descriptors source apps ui hierarchy widgets without explicit indicators functionalities rida generates semantic descriptors using image caption ing technique rida employs ontheﬂy bidirectional search algorithm analyze source event sequence identiﬁes appropriate target events via semantic matching considering widgets text information typically short length rida leverages partofspeech tagging reduce noises caused common words short texts facili tate semantic matching experiment results popular real world android apps show rida effective replaying controlled unspeciﬁed user events moreover ridas semantic matching algorithm outperforms stateoftheart approach baseline methods summary make four contributions paper best knowledge made ﬁrst attempt address technical challenges crossapp recordand replay help android app developers boost development process qa resources limited designed implemented rida practical tool employs ontheﬂy search algorithm image captioning technique realize recordandreplay across apps similar functionalities evaluated rida controlled experiment inthewild experiment showing rida effective replaying controlled unspeciﬁed user event sequences results demonstrate ridas usefulness crossapp recordandreplay tasks made ridas source code experiment data publicly available future researche nonrobust test execution common challenge automated guibased testing web applications evolve despite recent progress still room improvement since test execution failures caused technical limitations result unnecessary maintenance costs limit effectiveness efﬁciency one reported technical challenges webbased tests concerns reliably locate web element used test script paper proposes novel concept visually overlapping nodes von reduces fragility utilizing phenomenon visual web elements observed user constructed multiple webelements document object model dom overlaps visually demonstrate approach tool von similo extends stateoftheart multilocator approach similo also used baseline experiment experiment ground truth set manually collected web element pairs different releases popular web applications internet used compare approaches precision recall accuracy results show von similo provides accuracy identifying web element new release sut comparison similo provides accuracy results demonstrate applicability visually overlapping nodes concepttool web element localization evolving web applications contribute novel way thinking web element localization future research guibased testing index termscomponent formatting style styling insert modern software engineering test automation key activity automated tests used continuously mon itor softwares quality provide frequent feedback developers however much automation restricted lowerlevel testing unit integration tests higher level testing particularly graphical user interface gui tests still mostly manual therefore costly activity practice gui tests used verify correctness guis appearance focus many gui tests verifying functional correctness system test sut ie system testing suts gui however despite continued research since several key challenges remain limit widespread adoption automated gui testing one challenges robust identiﬁcation gui elements issue described many domains several approaches proposed increase robustness gui element localization robustness instance deﬁned correct identiﬁcation web element available reporting match web element unavailable property particularly important automated web appli cation tests typically used regression testing software systems gui elements change evolve despite importance research marginal success solving challenge robust gui element localization instead much research focused extending gui testing technologies utilizing already available web element localization solutionsexample extensions test generation gui ripping research however made investigating new types locators eg image recognition multilocators however still consider web element localization unsolved chal lenge warranting research improve general robustness maintainability available gui testing tech niques tools nass et al proposed approach called similaritybased web element localization similo calculates weighted similarity score target web element previous version web elements candidates revised version web application target web element contains desired properties eg attributes compared candidate compared similo approach multilocator approach proposed leotta et al found similo correctly locate target web elements multilocator evaluating web elements extracted commonly used homepages study presents novel concept visually lapping nodes von concept makes use struc ture modern web applications constructed ie hierarchies components speciﬁc attributes characteristics structure formalized document object model dom investigations show multiple dom nodes often point visual element rendered gui implying nodes found match sought visual element constitute valid match used graphic validation sut dom nodes typically arranged hierarchy represent visual element eg button menu item ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply fig graphical representation gui test case execution process highlighting step web element identiﬁcation studied work paper referred visually overlapping nodes von example menu item represented anchor tag containing two span tags span dom three dom nodes visually appear element observed user even though three separate nodes beneﬁt approach increases chance ﬁnd least one good match provided target thus leading robust web element identiﬁcation many essential activities need place robust guibased test automation focus vital aspect gui web element identiﬁcation identiﬁcation robust later steps chain cannot compensate focus visualized figure main contributions work insights relative power different web element attributes web element localization generally applicable yet novel concept called visually overlapping nodes von improved version similaritybased web element lo calization similo implements von von similo continuation paper structured follows first section ii present related work give detailed descriptions technologies evaluated study section iv explains studys experimental setup present results section va describes ﬁndings experiment ﬁndings discussed section vi paper concluded section ve students test inherently belongs programming explicitly asked index termsprogramming education software testing di dactic approach software testing important skill required software engineers nevertheless testing often taught late computer science curricula research demonstrated integrating software testing early programming courses many beneﬁts improving students performance providing better feedback students objective grading drawbacks integrating testing process however introductory programming courses still many scatalon et al identiﬁed following drawbacks negative attitude students towards testing even though might recognise importance courses already packed integrating testing means additional topics course amount lecture hours additional workload needed adapt course course materials include testing paper present tile test informed learning examples approach introduce software testing introductory programming courses following ways early introduce students testing ﬁrst example program see write exercises seamless testing introduced smooth con tinuous way inherent part programming separate activity subtle make use clever indirect methods teach testing knowledge skills convinced tile help solve least soften part drawbacks mentioned students negative attitude towards testing comes fact see something separated programming testing seen tangential really matters writing program solve problem introduce testing late students consider gives work needed tile introduce testing separate activity presented used inherent part programming early possible regarding packed programming courses advocate testing seen additional topic cover teaching programming right way moreover educators idea adding testing means adding work testing left interchanged another topic convey message students contributing negative attitude towards testing regarding additional workload introducing tile tileing examples exercises take effort increase workload nevertheless tile show paper comes open source repository educators access exercises ideas easily use mix adapt courses contributions paper presenting tile new concept create testaware introductory programming courses initial exploratory experiment establish groundwork research ﬁrst experiences takeaways using tile open repository tiled assignments instructors worldwide freely use rest paper structured follows section ii describes related work section iii introduce main ideas behind tile sections iv v vi give detailed description different types tiles section vii discusses initial exploratory experiment tiled exercises ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply section viii describes open repository way contribute section ix describes anecdotal evidence followed section x gives indication testing books used introductory programming courses need tile ﬁnally section xi concludes use acronym ﬂexibility term tile paper use tile noun verb adjective ie circles squares etc isa relation e example executions coded programs objects first java example ﬁrst instances class circle created calling constructor subsequently methods invoked instance see happens e example problems students need solve exercisesregression testing regularly performed software sys inad tems ensure existing system behavior vertently affected changes however increasingly large test suites shorter software delivery lifecycles need reduce feedback time development arises regression test prioritization rtp aims reduce feedback time developers running tests earlier likely reveal faults yet since testers cannot know advance test case fails surrogates used order tests rtp approaches using different kinds surrogates proposed past two decades existing approaches harness whitebox information code coverage textual test case similarity program changes test code code quality metrics blackbox information test input diversity version control system metadata failure history automotive domain systemlevel regression testing particularly complex test cases typically require interplay embedded hardware software components order successfully executed result testing commonly performed manually making especially costly often systemlevel testing done blackbox manner since neither code artifacts information components external suppliers available testers characteristics naturally limit applicability rtp approaches use information beyond blackbox information numerous rtp studies investigate effectiveness blackbox rtp approaches however several limitations studies automotive domain first test failures typically regarded equally severe yet given context assumption hold true failure test case covers safetycritical requirements severe test covering requirements second availability absence historical data pose signiﬁcant challenges design evaluation rtp approaches instance historical test plans available deﬁning realistic baseline random test ordering non trivial last several rtp approaches rely machine learning ml algorithms requiring signiﬁcant amounts training data cannot guaranteed available also ml based rtp approaches rarely compared searchbased heuristicsbased approaches industrial context even though latter shown work well instance context continuous integration ci address limitations case study investigates effectiveness several rtp approaches industrial setting systemlevel regression testing man particularly apply set purely blackbox rtp approaches suitable even little historical test execution data authors contributed equally man truck bus one leading international providers commercial vehicles ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply available design instantiate domain speciﬁc severityaware rtp assessment model allows us account varying failure severity also generate contextspeciﬁc rtp baselines realistically reﬂect test prioritization performed manually testers comparatively evaluate baselines rtp approaches industrial systemlevel regression test suite man results study indicate well known rtp surrogates based historical failures work well improve increasing amount historical data domainspeciﬁc failure severity models required produce adequate test orderings context automotive software engineering neither multiobjective advanced ml based rtp approaches provide signiﬁcant beneﬁts compared simple singleobjective approaches summary work makes following contributions severityaware rtp assessment model systemlevel regression testing automotive domain empirical evaluation stateoftheart blackbox rtp approaches severityunaware severityaware industrial case study demonstrating rtp tech niques reduce testing feedback time automotive software engineering mane statements tool supports different important features fault localization supporting sbfl formulas different tiebreaking methods showing code elements different colors ranging suspicious red suspicious green based suspicious scores allowing user deﬁne hisher formula etc using tool could help developers efﬁciently ﬁnd locations different types faults programs programs play important role daytoday activities nonetheless errors faults still exist critical may serious consequences thus several software fault localization approaches imple mented spectrumbased fault localization sbfl sbfl level suspiciousness faulty program entity computed depending program spectra acquired performing set test cases however widespread industry sector issues one problem sbfl tools focus cc java programs therefore lacks support developers debug software using languages python paper implement tool named sflaas service enable software fault localization process used anywhere anytime tool useful python developers easily analyze software generating data produce list suspicious elements runtime mark element suspicious element examined developer top list bottom suspicious element least one examine applicability tool python program uploaded see results outcome shows tool easy use beneﬁcial ﬁnding faults python programsch abstractunmanned aerial vehicles uavs also known drones acquiring increasing autonomy com mercial adoption problem testing functional nonfunctional particular safety requirements become critical concern simulationbased testing represents fundamental practice testing scenarios considered softwareintheloop testing may representative actual scenarios experienced ﬁeld paper propose surrealist testing uavs neighborhood real ﬂights novel searchbased approach analyses logs real uav ﬂights automatically generates simulationbased test cases neighborhood real ﬂights thereby improving realism representativeness simulationbased tests done two steps ﬁrst surrealist faithfully replicates given uav ﬂight simulation environment generating simulationbased test mirrors prelogged realworld behavior smoothly manipulates replicated ﬂight conditions discover slightly modiﬁed test cases challenging trigger misbehaviors uav test simulation experiments able replicate real ﬂight accurately simulation environment expose unstable potentially unsafe behavior neighborhood replicated ﬂight even led crashes index termsautonomous systems software testing un manned aerial vehicles boost cyberphysical systems cps academia industry past decade witnessed impressive advancements technology available health care avionics automotive railway robotics sectors unmanned aerial vehicles uavs drones equipped onboard cameras sensors already demonstrated autonomous ﬂights possible real environments sparked great interest plethora application scenarios crop monitoring surveillance medical food delivery search rescue disaster areas representing relevant applications uavs support uav developers increased years openaccess projects software ie ﬁrmware hardware eg ﬂight controller wellknown examples ardupilot px autopilot software pix hawk open standards uav hardware hand automated testing uavs general cps ensure proper behavior represents still open research challenge simulationbased testing promising direction improve uav testing practices researchers proposed use digitaltwins ie virtual representations realtime physical objects processes simulate test cps diversiﬁed scenarios support test automation however challenging capture bugs physical tests simulation generate rep resentative simulated test cases expose realistic bugs better illustrate problem statement let us consider following scenario bob uav customer using quad copter based px popular opensource uav ﬁrmware enabling autonomous ﬂight path planning obstacle avoid ance crop monitoring missions various croplands since lands close include trees buildings roads populated areas facilities particularly concerned safety reliability quadcopter missions already tested uav speciﬁc scenario one lands autonomous ﬂight starting point destination point crossing small building way bob observed uav reached destination safely avoiding obstacles scene yet convinced case possible scenarios lands speciﬁcally interested know uav would still complete mission safely even scenario bit different egdifferent building sizes planned paths weather conditions since budget test uav variations manually ﬁeld bob contacts alice experienced px developer help safety assessment uav diversiﬁed scenarios ﬁrst step alice asks bob flight logs ﬁeld tests logs include valuable information environment perceived uav ﬂights eg sensor readings received commands motor control signals alice challenge manually analyzing ﬂight logs interpreting results test investigating ways make proper assessment drone alternative neighboring ﬂight scenarios practical viable strategy alice decides use simulators eg gazebo replicate real test ﬂights simulation identify closerelated ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply scenarios could potentially fail real world however problem replicating logged real ﬂight simulation high ﬁdelity remains big issue alice context work assume uav behavior simulation line behavior ﬁeld eg trajectory ﬂight simulated replication considered realistic questions enable alice faithfully replicate real uav ﬂight simulation analyz ing ﬂight log coming unknown environment enable alice test uav set diversiﬁed possible scenarios neighborhood given ﬁeld test software engineering researchers proposed several auto mated solutions generate test cases reproducing crashes softwareonly systems however best knowledge existing approach cpsuav testing addresses problem test scenario replication test case generation execution state reproduced state program involves also state real world paper propose surrealist testing uavs neighborhood real ﬂights novel searchbased approach automatically generates simulationbased test cases neighborhood previously logged realworld uav ﬂights thereby improving realism softwareinthe loop testing using approach work done alice previous scenario drastically reduced simply giving bobs ﬂight log input surrealist following steps described section iii approach ﬁrst analyses ﬂight log extracts available uav environment con ﬁgurations searches optimal values unknown conﬁgurations replicate realworld uav behavior simulation environment smoothly manipulates replicated conﬁgurations ﬂight conditions discover related test scenarios potentially trigger unsafe behavior uav simulation also guide bob toward potential corner cases ﬁeld testing paper provides following contributions generic approach automatically generating simulationbased test case replicates real ﬂight sce nario searching optimal simulation environment conﬁgurations using ﬂight log generic approach automatically modiﬁes repli cated simulationbased test case generate chal lenging test scenarios empirical evaluation speciﬁc instance generic approaches optimal placement obstacles simulation environment autonomous ﬂight replication package github including surre alist implementation experiments data resultsgive industrial perspective research challenges concerned three broadly related areas software testing optimisation improvement research software test generation section ii automated repair improvement section iii automated transplantation refactoring section iv section v consider opportunities incorporation artificial intelligence techniques tackling problems right combination existing section vi software engineering research finally collect together lessons learned previous work industrial deployment software testing improvement researchtesting art checking program works scenarios order gain evidence works basic form developer must manually create set sample inputs expected behavior years haskell community boasted ability automate writing properties letting property based testing tool generate inputs automatically replaces hard labor hard thought still difﬁcult think right properties yet every program implies set properties gener ating testing vast number properties might hold given program developer need merely select smörgåsbord hold idea quickspec capable generating interesting properties numerous data structures starting list functions consider long list small beyond single digits exponential growth overwhelms search abilities introduce spectacular new tool automati cally discovering program properties uses advances program synthesis search spaces candidate programs ordersofmagnitude larger searched quickspec example functions constants figure spectacular ﬁnds laws compared quickspecs even running restricted mode still ﬁnds laws quickspec less half time thanks use recentlyintroduced ecta equalityconstrained tree automata data structure capable compactly representing space trillions possible programs efﬁciently enumerating ones welltyped satisfy property encodable main tacularspec con reverse reverse con con con map map b b con length length int con concat concat con int con int figure example signature spectacular presentation slightly simpliﬁed drop xs xs sort xs sort reverse xs reverse reverse xs xs reverse xs ys reverse ys reverse xs map f concat lists concat map map f lists length xs ys length xs length ys figure example laws generated spectacular signature ﬁgure equality constraints beneﬁts quickspec get larger larger modules thanks ectas custom enumeration spectacular start generating laws within minutes space terms size signature functions constants space tril lion terms memory consumption never exceeding gb quickspec benchmark gets stuck enumerating terms size crashes memory exhaustion minutes machine gb ram loc compared quickspecs summary paper makes following contributions automated program property discovery approach based modern program synthesis techniques specif ically ectas spectacular tool capable discovering program properties ordersofmagnitude faster previous ap proaches large examples source available httpszenodoorgrecord along scripts used generate benchmarks evaluation note spectacular spectacular subfolder ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply eclass eclass f eclass b c q q f q b f f b f c c q q f q b c egraph b fta c egraph u ecta u figure representations ft f u ft f b csoftware testing aims ﬁnd faults behavior systemundertest sut execution test cases test case applies input sut judges subsequent output using test oracleembedded expectations output often form assertions testing especially important safetycritical domains automotive industry since undetected faults lead life threatening failures risks failure intensify systems grow complex case emergence autonomous vehicles machine learning ml core functionality autonomous vehicles supporting tasks collision avoidance lanekeeping common form ml supervised learning trains model make predictions using labeled training data autonomous vehicles example emerging category ml systemssoftware systems contain components depend ml eg use model basis functional logic ml systems present new testing challenges example ml algorithms models usually nondeterministic introducing challenges specifying expected output addition many ml problems large input spaceeg potential trafﬁc situationsmaking challenging identify failurerevealing test inputs finally common ways measuring well system tested eg code coverage cannot applied ml systems behavioral logic often embedded models instead code tests created sut typically require maintenance project evolves tests must updated eg requirements reﬁned new functionality implemented model retrained research conducted test maintenance past eg lack knowledge factors affect test maintenance ml systems past research traditional systems may directly applicable due differences system design behavior ml traditional systems purpose study gain understanding factors affect test maintenance ml systems well make recommendations minimize improve maintenance process end conducted exploratory case study zenseact company specializing software autonomous driving study motivated three challenges encountered zenseact regarding test design maintenance ml systems first developers encountered ﬂaky test cases yield inconsistent results second noticed test cases often updated retraining ml model changed predictions caused test failures causing testers expend effort communicate teams understand whether failure fault revealing indicative need test maintenance ie updating test oracle finally ml systems challenging test unit level components cannot tested isolation withoutat leastintegration model conducted semistructured interview study artifact analysis identify test maintenance factors examine inﬂuence ﬂaky tests test maintenance provide recommendations reducing test maintenance effort addition compared results test maintenance factors reported past research traditional systems ulti mately observed nine factors identiﬁed affect test maintenance systems continuity scenario setup es pecially relevant automotive context additional factors affect maintenance ml systems include ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply figure example ml system including ﬂow model components sensor provides input amount quality training data nondeterminism explainability input space size testing granularity main differences ml traditional systems degree determinism explainability code scope testing granularity clear ﬂaky tests inﬂuence test maintenance ml systems differently traditional systems ml systems result tests ﬂaky behaviorbecause sut nondeterministicbut tests inherently ﬂaky discussion threads test cases show inﬂuence nondeterminism testing granularity explainability communication test maintenance particular non determinism creates need test maintenance introduces challenges regard explainability communication knowledge sharing maintainer tags slack bots test driven development detailed failure messages uniﬁed scenario setup improve reduce test mainte nance systems ml systems tolerant oracles forced determinism isolation consistent hardware propertybased testing impact ﬁndings offer insights test maintenance ml sys tems industrial context offer observations recommendations researchers practitioners inspire future advances rapidly evolving arearesearch focus spectrumbased fault localiza tion sbfl many empirical studies focused standing improving fault localization technique uses coverage data passfail results test cases ie programs spectra using given spectra assigns suspiciousness scores code element sorts code elements ranked list based suspiciousness scores developer uses ranked list program locations guide debugging lack implementation fault localization techniques due poor ranking performance reliance statistical probability techniques use program spectra leading unsuc cessful localization wasted time investigating nonfaulty code improving sbfls success rate crucial goal improve performance utilizing context information sbfl takes account programs spectra information idea behind using context information certain code elements bug features bug ﬁxes likely problematic others using patterns machine learning mod els code structure etc represent context information enhance performance sbfl another way enhance success localization assisting developer debugging utilize program way developers prior knowledge provide feedback localized code element algorithm recalculates suspiciousness scores using feedback however heavily relies developers level knowledge sbfl algorithm also explain code element faulty consider following contexts yet identify static dynamic program structure user feedback data software repository data bug reports change logs etcstatic program analysis clients used diverse applica tion domains including compiler optimization bug vulnerability detection featurebased classiﬁcation client analyses tailored depending requirements domain yet independent domain client analyses require pointer information purpose sometimes implement pointer analysis part client analysis frequently use preexisting pointer analysis fast precise pointer analysis still open challenge largescale programs precise pointer analyses track calling contexts ﬁelds statements hinder scalability scalable many current pointer analyses performed demanddriven manner opposed conducting exhaustive whole program analysis beneﬁt fact client analyses frequently require pointer information certain variables certain program points instance assume direct assignment taint analysis eg xf tainted aliases x need known taint analysis analysis taint f ﬁelds xs aliases demanddriven pointer analyses exploit compute alias information variables clients raise demand query yet previous work shown even demanddriven analyses expensive run largescale programs boomerang stateoftheart demanddriven pointer analysis framework uses synchronized pushdown systems spds pushdown systems pds applicable contextfree language reachability problems context ﬁeldsensitivity modeled boomerang synchronizes two pds model context ﬁeldsensitivity respectively pds depend rules correspond dataﬂow functions work exploit many rules redundant affect dataﬂow facts matter end result dataﬂow facts pointer analysis correspond variables aliases redundant rules exist control ﬂow graphs cfg contain statements affect alias relationships also many statements beauty demand driven pointer analysis one knows exact query variable ie variable whose aliases queried ahead analysis time therefore answering raised demand one sparsify cfg removing statements irrelevant result particular query variable thus omit redundant rules construction spds previous work successfully applied sparsiﬁcation improve scalability general dataﬂow analyses pointer analysis particular approaches create sparse versions cfgs target program sparse versions often called sparse value ﬂow graphs svfgs sparse control ﬂow graphs scfgs previous approaches create scfgs preanalysis stage whole program thus settle information available stage recent work et al showed one increase sparseness ie omit cfg irrelevant statements specializing ieee doi icst authorized licensed use limited universidade de sao paulo downloaded april utc ieee xplore restrictions apply scfgs individual dataﬂow facts work applied ifds framework applicable distributive analysis problems pointer analysis known nondistributive work thus investigate extent one make use idea factspeciﬁc sparseness nonetheless also pointer analysis proposed framework sparseboomerang analysis creates new scfg speciﬁc queried value goal sparsiﬁcation speed analysis run restricting fewer program statements ideally generating results identical exhaustive analysis yet creation scfgs incurs cost terms memory runtime sparsiﬁcation pays savings evaluating sparse graph comparison original exhaustive graph outweigh construction time investigate performance tradeoff work present two sparsiﬁcation strategies different degrees sparsiﬁcation strategies create ondemand scfgs speciﬁc alias query first typeaware sparsiﬁcation tas resulting cfg consists statements containing variables type compatible query variable second aliasaware sparsiﬁcation aas resulting cfg consists defuse chains query variable intraprocedural aliases strategies mirror designs published earlier context virtual call resolution declaredtype analysis dta variable type analysis vta respectively dta vta create signment chains node represents variable either declared type dta vta strategies create defuse chains node represents statement either types tas variables aas contains evaluate applicability proposed two sparsiﬁcation strategies within spds framework implement sparseboomerang extending spdsbased boomerang validate whether two sparsiﬁcation strategies maintain precision original exhaustive boomerang run approaches pointerbench benchmark suite alias analysis evaluate performance impact strategies run boomerang sparseboomerang realworld android applications end extend flowdroid stateoftheart taint analysis client android applications creates ondemand alias queries boomerang sparseboomerang evaluation results show sparseboomerang using either sparsiﬁcation strategies solves alias queries average twice faster boomerang maintaining full precision performance gains achieved demanddriven pointer analysis reﬂected taint analysis client flowdroid sparseboomerang maintains boomerangs precision modiﬁcation flowdroid uses demand driven pointer analyses boomerang sparse boomerang performance evaluation real world android apps remainder paper organized follows section ii present background work based section iii introduce ondemand sparsiﬁcation strategies section iv explain implementation de tails sparseboomerang section v presents results obtained evaluations section vi discuss limitations approach threats validity section vii discuss related work conclude sectionvi